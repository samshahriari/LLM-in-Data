{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hFtIoOS1miX"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "def dot_prod(inputs,w):\n",
        "    z = w[0]  # this is the bias\n",
        "    for i in range(1,4):\n",
        "        z += inputs[i-1] * w[i]\n",
        "    return z\n",
        "\n",
        "def ReLU(x,derivative = False):\n",
        "    if x>=0 and not derivative:\n",
        "        return x\n",
        "    if x>=0:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "def sigmoid(x,derivative = False):\n",
        "    if not derivative:\n",
        "        return 1/(1 +  math.exp(-x))\n",
        "    else:\n",
        "        return sigmoid(x)*(1-sigmoid(x))\n",
        "\n",
        "def tanh(x,derivative = False):\n",
        "    if not derivative:\n",
        "        return math.tanh(x)\n",
        "    else:\n",
        "        return 1 - math.tanh(x)**2\n",
        "\n",
        "def uniform_0_1():\n",
        "    return random.random()\n",
        "\n",
        "def uniform_m1_p1():\n",
        "    return (random.random() * 2) - 1\n",
        "\n",
        "def zeros():\n",
        "    return 0\n",
        "\n",
        "def forward_and_backward(example, g, w):\n",
        "    grad = [0, 0, 0, 0]\n",
        "    dot = dot_prod(example[0],w)\n",
        "    answer = g(dot)\n",
        "    err =  example[1] - answer\n",
        "    loss = .5 * (err **2)\n",
        "    derivative = g(dot, derivative=True)\n",
        "    grad[0] = -err * derivative * 1\n",
        "    for i in range(1, 4):\n",
        "        grad[i] = -err * derivative * example[0][i - 1]\n",
        "    return answer,err,loss,grad\n",
        "\n",
        "def update(gradient, w):\n",
        "    for i in range(0,4):\n",
        "        w[i] = w[i] - learning_rate * gradient[i]\n",
        "\n",
        "def train(g, examples, initial_weight_distribution, epochs=100, print_weights=False):\n",
        "    w = [initial_weight_distribution() for i in range(4)]\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for example in examples:\n",
        "            answer,err,loss,grad = forward_and_backward(example, g, w)\n",
        "            total_loss += loss\n",
        "            if print_weights:\n",
        "                print(f\"weights: {w[0]:.4f} {w[1]:.4f} {w[2]:.4f} {w[3]:.4f}\")\n",
        "            print(f\"{str(example)}:{answer:.4f}, error={err:.4f}, loss={loss:.4f}, grad={grad[0]:.4f} {grad[1]:.4f} {grad[2]:.4f} {grad[3]:.4f}\")\n",
        "            update(grad, w)\n",
        "        print(f\"epoch{epoch}, average loss {total_loss/len(examples):.4f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "majority = [\n",
        "[[0,0,0],0],\n",
        "[[0,0,1],0],\n",
        "[[0,1,0],0],\n",
        "[[1,0,0],0],\n",
        "[[0,1,1],1],\n",
        "[[1,0,1],1],\n",
        "[[1,1,0],1],\n",
        "[[1,1,1],1]\n",
        "]\n",
        "xor = [[[0,0,0],0],\n",
        "[[0,0,1],1],\n",
        "[[0,1,0],1],\n",
        "[[1,0,0],1],\n",
        "[[0,1,1],0],\n",
        "[[1,0,1],0],\n",
        "[[1,1,0],0],\n",
        "[[1,1,1],0]]\n",
        "\n",
        "one_wire_not = [\n",
        "  [[0,0,0],1],\n",
        "  [[0,0,1],1],\n",
        "  [[0,1,0],1],\n",
        "  [[0,1,1],1],\n",
        "  [[1,0,0],0],\n",
        "  [[1,0,1],0],\n",
        "  [[1,1,0],0],\n",
        "  [[1,1,1],0]\n",
        "                 ]\n",
        "#1\n",
        "train(tanh, xor,uniform_0_1,epochs=100,print_weights=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktI6X_Ef2FAe",
        "outputId": "fdc53687-4ce7-486e-a552-eadb72dd34f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights: 0.5581 0.9734 0.4002 0.0105\n",
            "[[0, 0, 0], 0]:0.5066, error=-0.5066, loss=0.1283, grad=0.3766 0.0000 0.0000 0.0000\n",
            "weights: 0.5543 0.9734 0.4002 0.0105\n",
            "[[0, 0, 1], 1]:0.5115, error=0.4885, loss=0.1193, grad=-0.3607 -0.0000 -0.0000 -0.3607\n",
            "weights: 0.5579 0.9734 0.4002 0.0141\n",
            "[[0, 1, 0], 1]:0.7434, error=0.2566, loss=0.0329, grad=-0.1148 -0.0000 -0.1148 -0.0000\n",
            "weights: 0.5591 0.9734 0.4014 0.0141\n",
            "[[1, 0, 0], 1]:0.9108, error=0.0892, loss=0.0040, grad=-0.0152 -0.0152 -0.0000 -0.0000\n",
            "weights: 0.5592 0.9736 0.4014 0.0141\n",
            "[[0, 1, 1], 0]:0.7507, error=-0.7507, loss=0.2818, grad=0.3276 0.0000 0.3276 0.3276\n",
            "weights: 0.5559 0.9736 0.3981 0.0108\n",
            "[[1, 0, 1], 0]:0.9122, error=-0.9122, loss=0.4160, grad=0.1532 0.1532 0.0000 0.1532\n",
            "weights: 0.5544 0.9720 0.3981 0.0093\n",
            "[[1, 1, 0], 0]:0.9583, error=-0.9583, loss=0.4592, grad=0.0783 0.0783 0.0783 0.0000\n",
            "weights: 0.5536 0.9712 0.3973 0.0093\n",
            "[[1, 1, 1], 0]:0.9589, error=-0.9589, loss=0.4597, grad=0.0773 0.0773 0.0773 0.0773\n",
            "epoch0, average loss 0.2376 \n",
            "\n",
            "weights: 0.5529 0.9705 0.3965 0.0085\n",
            "[[0, 0, 0], 0]:0.5027, error=-0.5027, loss=0.1263, grad=0.3757 0.0000 0.0000 0.0000\n",
            "weights: 0.5491 0.9705 0.3965 0.0085\n",
            "[[0, 0, 1], 1]:0.5062, error=0.4938, loss=0.1219, grad=-0.3673 -0.0000 -0.0000 -0.3673\n",
            "weights: 0.5528 0.9705 0.3965 0.0122\n",
            "[[0, 1, 0], 1]:0.7395, error=0.2605, loss=0.0339, grad=-0.1181 -0.0000 -0.1181 -0.0000\n",
            "weights: 0.5540 0.9705 0.3977 0.0122\n",
            "[[1, 0, 0], 1]:0.9095, error=0.0905, loss=0.0041, grad=-0.0157 -0.0157 -0.0000 -0.0000\n",
            "weights: 0.5541 0.9706 0.3977 0.0122\n",
            "[[0, 1, 1], 0]:0.7461, error=-0.7461, loss=0.2783, grad=0.3308 0.0000 0.3308 0.3308\n",
            "weights: 0.5508 0.9706 0.3944 0.0089\n",
            "[[1, 0, 1], 0]:0.9105, error=-0.9105, loss=0.4145, grad=0.1557 0.1557 0.0000 0.1557\n",
            "weights: 0.5492 0.9691 0.3944 0.0073\n",
            "[[1, 1, 0], 0]:0.9573, error=-0.9573, loss=0.4582, grad=0.0800 0.0800 0.0800 0.0000\n",
            "weights: 0.5484 0.9683 0.3936 0.0073\n",
            "[[1, 1, 1], 0]:0.9577, error=-0.9577, loss=0.4586, grad=0.0793 0.0793 0.0793 0.0793\n",
            "epoch1, average loss 0.2370 \n",
            "\n",
            "weights: 0.5477 0.9675 0.3928 0.0065\n",
            "[[0, 0, 0], 0]:0.4988, error=-0.4988, loss=0.1244, grad=0.3747 0.0000 0.0000 0.0000\n",
            "weights: 0.5439 0.9675 0.3928 0.0065\n",
            "[[0, 0, 1], 1]:0.5008, error=0.4992, loss=0.1246, grad=-0.3740 -0.0000 -0.0000 -0.3740\n",
            "weights: 0.5476 0.9675 0.3928 0.0103\n",
            "[[0, 1, 0], 1]:0.7354, error=0.2646, loss=0.0350, grad=-0.1215 -0.0000 -0.1215 -0.0000\n",
            "weights: 0.5489 0.9675 0.3940 0.0103\n",
            "[[1, 0, 0], 1]:0.9081, error=0.0919, loss=0.0042, grad=-0.0161 -0.0161 -0.0000 -0.0000\n",
            "weights: 0.5490 0.9676 0.3940 0.0103\n",
            "[[0, 1, 1], 0]:0.7413, error=-0.7413, loss=0.2747, grad=0.3340 0.0000 0.3340 0.3340\n",
            "weights: 0.5457 0.9676 0.3907 0.0069\n",
            "[[1, 0, 1], 0]:0.9087, error=-0.9087, loss=0.4129, grad=0.1583 0.1583 0.0000 0.1583\n",
            "weights: 0.5441 0.9661 0.3907 0.0053\n",
            "[[1, 1, 0], 0]:0.9563, error=-0.9563, loss=0.4573, grad=0.0817 0.0817 0.0817 0.0000\n",
            "weights: 0.5433 0.9652 0.3899 0.0053\n",
            "[[1, 1, 1], 0]:0.9566, error=-0.9566, loss=0.4575, grad=0.0813 0.0813 0.0813 0.0813\n",
            "epoch2, average loss 0.2363 \n",
            "\n",
            "weights: 0.5425 0.9644 0.3891 0.0045\n",
            "[[0, 0, 0], 0]:0.4949, error=-0.4949, loss=0.1224, grad=0.3737 0.0000 0.0000 0.0000\n",
            "weights: 0.5387 0.9644 0.3891 0.0045\n",
            "[[0, 0, 1], 1]:0.4954, error=0.5046, loss=0.1273, grad=-0.3807 -0.0000 -0.0000 -0.3807\n",
            "weights: 0.5425 0.9644 0.3891 0.0083\n",
            "[[0, 1, 0], 1]:0.7313, error=0.2687, loss=0.0361, grad=-0.1250 -0.0000 -0.1250 -0.0000\n",
            "weights: 0.5438 0.9644 0.3903 0.0083\n",
            "[[1, 0, 0], 1]:0.9066, error=0.0934, loss=0.0044, grad=-0.0166 -0.0166 -0.0000 -0.0000\n",
            "weights: 0.5440 0.9646 0.3903 0.0083\n",
            "[[0, 1, 1], 0]:0.7364, error=-0.7364, loss=0.2711, grad=0.3371 0.0000 0.3371 0.3371\n",
            "weights: 0.5406 0.9646 0.3869 0.0050\n",
            "[[1, 0, 1], 0]:0.9070, error=-0.9070, loss=0.4113, grad=0.1609 0.1609 0.0000 0.1609\n",
            "weights: 0.5390 0.9630 0.3869 0.0033\n",
            "[[1, 1, 0], 0]:0.9553, error=-0.9553, loss=0.4563, grad=0.0835 0.0835 0.0835 0.0000\n",
            "weights: 0.5381 0.9621 0.3861 0.0033\n",
            "[[1, 1, 1], 0]:0.9553, error=-0.9553, loss=0.4563, grad=0.0834 0.0834 0.0834 0.0834\n",
            "epoch3, average loss 0.2357 \n",
            "\n",
            "weights: 0.5373 0.9613 0.3853 0.0025\n",
            "[[0, 0, 0], 0]:0.4909, error=-0.4909, loss=0.1205, grad=0.3726 0.0000 0.0000 0.0000\n",
            "weights: 0.5336 0.9613 0.3853 0.0025\n",
            "[[0, 0, 1], 1]:0.4900, error=0.5100, loss=0.1300, grad=-0.3875 -0.0000 -0.0000 -0.3875\n",
            "weights: 0.5375 0.9613 0.3853 0.0064\n",
            "[[0, 1, 0], 1]:0.7272, error=0.2728, loss=0.0372, grad=-0.1286 -0.0000 -0.1286 -0.0000\n",
            "weights: 0.5387 0.9613 0.3865 0.0064\n",
            "[[1, 0, 0], 1]:0.9052, error=0.0948, loss=0.0045, grad=-0.0171 -0.0171 -0.0000 -0.0000\n",
            "weights: 0.5389 0.9615 0.3865 0.0064\n",
            "[[0, 1, 1], 0]:0.7315, error=-0.7315, loss=0.2675, grad=0.3401 0.0000 0.3401 0.3401\n",
            "weights: 0.5355 0.9615 0.3831 0.0030\n",
            "[[1, 0, 1], 0]:0.9051, error=-0.9051, loss=0.4096, grad=0.1636 0.1636 0.0000 0.1636\n",
            "weights: 0.5339 0.9598 0.3831 0.0013\n",
            "[[1, 1, 0], 0]:0.9542, error=-0.9542, loss=0.4553, grad=0.0854 0.0854 0.0854 0.0000\n",
            "weights: 0.5330 0.9590 0.3823 0.0013\n",
            "[[1, 1, 1], 0]:0.9541, error=-0.9541, loss=0.4552, grad=0.0856 0.0856 0.0856 0.0856\n",
            "epoch4, average loss 0.2350 \n",
            "\n",
            "weights: 0.5322 0.9581 0.3814 0.0005\n",
            "[[0, 0, 0], 0]:0.4870, error=-0.4870, loss=0.1186, grad=0.3715 0.0000 0.0000 0.0000\n",
            "weights: 0.5285 0.9581 0.3814 0.0005\n",
            "[[0, 0, 1], 1]:0.4846, error=0.5154, loss=0.1328, grad=-0.3944 -0.0000 -0.0000 -0.3944\n",
            "weights: 0.5324 0.9581 0.3814 0.0044\n",
            "[[0, 1, 0], 1]:0.7230, error=0.2770, loss=0.0384, grad=-0.1322 -0.0000 -0.1322 -0.0000\n",
            "weights: 0.5337 0.9581 0.3828 0.0044\n",
            "[[1, 0, 0], 1]:0.9037, error=0.0963, loss=0.0046, grad=-0.0177 -0.0177 -0.0000 -0.0000\n",
            "weights: 0.5339 0.9583 0.3828 0.0044\n",
            "[[0, 1, 1], 0]:0.7264, error=-0.7264, loss=0.2638, grad=0.3431 0.0000 0.3431 0.3431\n",
            "weights: 0.5305 0.9583 0.3793 0.0010\n",
            "[[1, 0, 1], 0]:0.9033, error=-0.9033, loss=0.4080, grad=0.1663 0.1663 0.0000 0.1663\n",
            "weights: 0.5288 0.9567 0.3793 -0.0007\n",
            "[[1, 1, 0], 0]:0.9531, error=-0.9531, loss=0.4542, grad=0.0873 0.0873 0.0873 0.0000\n",
            "weights: 0.5279 0.9558 0.3785 -0.0007\n",
            "[[1, 1, 1], 0]:0.9528, error=-0.9528, loss=0.4539, grad=0.0878 0.0878 0.0878 0.0878\n",
            "epoch5, average loss 0.2343 \n",
            "\n",
            "weights: 0.5271 0.9549 0.3776 -0.0015\n",
            "[[0, 0, 0], 0]:0.4831, error=-0.4831, loss=0.1167, grad=0.3704 0.0000 0.0000 0.0000\n",
            "weights: 0.5233 0.9549 0.3776 -0.0015\n",
            "[[0, 0, 1], 1]:0.4791, error=0.5209, loss=0.1357, grad=-0.4013 -0.0000 -0.0000 -0.4013\n",
            "weights: 0.5274 0.9549 0.3776 0.0025\n",
            "[[0, 1, 0], 1]:0.7187, error=0.2813, loss=0.0396, grad=-0.1360 -0.0000 -0.1360 -0.0000\n",
            "weights: 0.5287 0.9549 0.3789 0.0025\n",
            "[[1, 0, 0], 1]:0.9021, error=0.0979, loss=0.0048, grad=-0.0182 -0.0182 -0.0000 -0.0000\n",
            "weights: 0.5289 0.9551 0.3789 0.0025\n",
            "[[0, 1, 1], 0]:0.7213, error=-0.7213, loss=0.2601, grad=0.3460 0.0000 0.3460 0.3460\n",
            "weights: 0.5254 0.9551 0.3755 -0.0010\n",
            "[[1, 0, 1], 0]:0.9014, error=-0.9014, loss=0.4062, grad=0.1690 0.1690 0.0000 0.1690\n",
            "weights: 0.5238 0.9534 0.3755 -0.0027\n",
            "[[1, 1, 0], 0]:0.9520, error=-0.9520, loss=0.4531, grad=0.0892 0.0892 0.0892 0.0000\n",
            "weights: 0.5229 0.9525 0.3746 -0.0027\n",
            "[[1, 1, 1], 0]:0.9515, error=-0.9515, loss=0.4527, grad=0.0901 0.0901 0.0901 0.0901\n",
            "epoch6, average loss 0.2336 \n",
            "\n",
            "weights: 0.5220 0.9516 0.3737 -0.0036\n",
            "[[0, 0, 0], 0]:0.4792, error=-0.4792, loss=0.1148, grad=0.3692 0.0000 0.0000 0.0000\n",
            "weights: 0.5183 0.9516 0.3737 -0.0036\n",
            "[[0, 0, 1], 1]:0.4736, error=0.5264, loss=0.1386, grad=-0.4083 -0.0000 -0.0000 -0.4083\n",
            "weights: 0.5224 0.9516 0.3737 0.0005\n",
            "[[0, 1, 0], 1]:0.7144, error=0.2856, loss=0.0408, grad=-0.1399 -0.0000 -0.1399 -0.0000\n",
            "weights: 0.5238 0.9516 0.3751 0.0005\n",
            "[[1, 0, 0], 1]:0.9006, error=0.0994, loss=0.0049, grad=-0.0188 -0.0188 -0.0000 -0.0000\n",
            "weights: 0.5239 0.9518 0.3751 0.0005\n",
            "[[0, 1, 1], 0]:0.7161, error=-0.7161, loss=0.2564, grad=0.3489 0.0000 0.3489 0.3489\n",
            "weights: 0.5205 0.9518 0.3716 -0.0030\n",
            "[[1, 0, 1], 0]:0.8994, error=-0.8994, loss=0.4045, grad=0.1718 0.1718 0.0000 0.1718\n",
            "weights: 0.5187 0.9501 0.3716 -0.0047\n",
            "[[1, 1, 0], 0]:0.9508, error=-0.9508, loss=0.4520, grad=0.0912 0.0912 0.0912 0.0000\n",
            "weights: 0.5178 0.9492 0.3707 -0.0047\n",
            "[[1, 1, 1], 0]:0.9501, error=-0.9501, loss=0.4514, grad=0.0924 0.0924 0.0924 0.0924\n",
            "epoch7, average loss 0.2329 \n",
            "\n",
            "weights: 0.5169 0.9482 0.3698 -0.0056\n",
            "[[0, 0, 0], 0]:0.4753, error=-0.4753, loss=0.1130, grad=0.3679 0.0000 0.0000 0.0000\n",
            "weights: 0.5132 0.9482 0.3698 -0.0056\n",
            "[[0, 0, 1], 1]:0.4681, error=0.5319, loss=0.1415, grad=-0.4154 -0.0000 -0.0000 -0.4154\n",
            "weights: 0.5174 0.9482 0.3698 -0.0015\n",
            "[[0, 1, 0], 1]:0.7100, error=0.2900, loss=0.0421, grad=-0.1438 -0.0000 -0.1438 -0.0000\n",
            "weights: 0.5188 0.9482 0.3712 -0.0015\n",
            "[[1, 0, 0], 1]:0.8990, error=0.1010, loss=0.0051, grad=-0.0194 -0.0194 -0.0000 -0.0000\n",
            "weights: 0.5190 0.9484 0.3712 -0.0015\n",
            "[[0, 1, 1], 0]:0.7108, error=-0.7108, loss=0.2526, grad=0.3517 0.0000 0.3517 0.3517\n",
            "weights: 0.5155 0.9484 0.3677 -0.0050\n",
            "[[1, 0, 1], 0]:0.8974, error=-0.8974, loss=0.4027, grad=0.1746 0.1746 0.0000 0.1746\n",
            "weights: 0.5137 0.9467 0.3677 -0.0067\n",
            "[[1, 1, 0], 0]:0.9496, error=-0.9496, loss=0.4509, grad=0.0932 0.0932 0.0932 0.0000\n",
            "weights: 0.5128 0.9458 0.3667 -0.0067\n",
            "[[1, 1, 1], 0]:0.9487, error=-0.9487, loss=0.4500, grad=0.0948 0.0948 0.0948 0.0948\n",
            "epoch8, average loss 0.2322 \n",
            "\n",
            "weights: 0.5119 0.9448 0.3658 -0.0077\n",
            "[[0, 0, 0], 0]:0.4714, error=-0.4714, loss=0.1111, grad=0.3666 0.0000 0.0000 0.0000\n",
            "weights: 0.5082 0.9448 0.3658 -0.0077\n",
            "[[0, 0, 1], 1]:0.4625, error=0.5375, loss=0.1444, grad=-0.4225 -0.0000 -0.0000 -0.4225\n",
            "weights: 0.5124 0.9448 0.3658 -0.0035\n",
            "[[0, 1, 0], 1]:0.7055, error=0.2945, loss=0.0434, grad=-0.1479 -0.0000 -0.1479 -0.0000\n",
            "weights: 0.5139 0.9448 0.3673 -0.0035\n",
            "[[1, 0, 0], 1]:0.8974, error=0.1026, loss=0.0053, grad=-0.0200 -0.0200 -0.0000 -0.0000\n",
            "weights: 0.5141 0.9450 0.3673 -0.0035\n",
            "[[0, 1, 1], 0]:0.7054, error=-0.7054, loss=0.2488, grad=0.3544 0.0000 0.3544 0.3544\n",
            "weights: 0.5106 0.9450 0.3637 -0.0070\n",
            "[[1, 0, 1], 0]:0.8954, error=-0.8954, loss=0.4009, grad=0.1775 0.1775 0.0000 0.1775\n",
            "weights: 0.5088 0.9432 0.3637 -0.0088\n",
            "[[1, 1, 0], 0]:0.9484, error=-0.9484, loss=0.4497, grad=0.0953 0.0953 0.0953 0.0000\n",
            "weights: 0.5078 0.9423 0.3628 -0.0088\n",
            "[[1, 1, 1], 0]:0.9472, error=-0.9472, loss=0.4486, grad=0.0973 0.0973 0.0973 0.0973\n",
            "epoch9, average loss 0.2315 \n",
            "\n",
            "weights: 0.5069 0.9413 0.3618 -0.0097\n",
            "[[0, 0, 0], 0]:0.4675, error=-0.4675, loss=0.1093, grad=0.3653 0.0000 0.0000 0.0000\n",
            "weights: 0.5032 0.9413 0.3618 -0.0097\n",
            "[[0, 0, 1], 1]:0.4569, error=0.5431, loss=0.1475, grad=-0.4297 -0.0000 -0.0000 -0.4297\n",
            "weights: 0.5075 0.9413 0.3618 -0.0055\n",
            "[[0, 1, 0], 1]:0.7010, error=0.2990, loss=0.0447, grad=-0.1521 -0.0000 -0.1521 -0.0000\n",
            "weights: 0.5090 0.9413 0.3633 -0.0055\n",
            "[[1, 0, 0], 1]:0.8958, error=0.1042, loss=0.0054, grad=-0.0206 -0.0206 -0.0000 -0.0000\n",
            "weights: 0.5092 0.9415 0.3633 -0.0055\n",
            "[[0, 1, 1], 0]:0.6999, error=-0.6999, loss=0.2449, grad=0.3570 0.0000 0.3570 0.3570\n",
            "weights: 0.5056 0.9415 0.3598 -0.0090\n",
            "[[1, 0, 1], 0]:0.8933, error=-0.8933, loss=0.3990, grad=0.1804 0.1804 0.0000 0.1804\n",
            "weights: 0.5038 0.9397 0.3598 -0.0108\n",
            "[[1, 1, 0], 0]:0.9471, error=-0.9471, loss=0.4485, grad=0.0975 0.0975 0.0975 0.0000\n",
            "weights: 0.5029 0.9387 0.3588 -0.0108\n",
            "[[1, 1, 1], 0]:0.9457, error=-0.9457, loss=0.4472, grad=0.0999 0.0999 0.0999 0.0999\n",
            "epoch10, average loss 0.2308 \n",
            "\n",
            "weights: 0.5019 0.9377 0.3578 -0.0118\n",
            "[[0, 0, 0], 0]:0.4636, error=-0.4636, loss=0.1075, grad=0.3640 0.0000 0.0000 0.0000\n",
            "weights: 0.4982 0.9377 0.3578 -0.0118\n",
            "[[0, 0, 1], 1]:0.4514, error=0.5486, loss=0.1505, grad=-0.4369 -0.0000 -0.0000 -0.4369\n",
            "weights: 0.5026 0.9377 0.3578 -0.0075\n",
            "[[0, 1, 0], 1]:0.6965, error=0.3035, loss=0.0461, grad=-0.1563 -0.0000 -0.1563 -0.0000\n",
            "weights: 0.5042 0.9377 0.3593 -0.0075\n",
            "[[1, 0, 0], 1]:0.8941, error=0.1059, loss=0.0056, grad=-0.0213 -0.0213 -0.0000 -0.0000\n",
            "weights: 0.5044 0.9379 0.3593 -0.0075\n",
            "[[0, 1, 1], 0]:0.6943, error=-0.6943, loss=0.2410, grad=0.3596 0.0000 0.3596 0.3596\n",
            "weights: 0.5008 0.9379 0.3557 -0.0111\n",
            "[[1, 0, 1], 0]:0.8912, error=-0.8912, loss=0.3971, grad=0.1834 0.1834 0.0000 0.1834\n",
            "weights: 0.4989 0.9361 0.3557 -0.0129\n",
            "[[1, 1, 0], 0]:0.9458, error=-0.9458, loss=0.4473, grad=0.0997 0.0997 0.0997 0.0000\n",
            "weights: 0.4979 0.9351 0.3548 -0.0129\n",
            "[[1, 1, 1], 0]:0.9441, error=-0.9441, loss=0.4457, grad=0.1025 0.1025 0.1025 0.1025\n",
            "epoch11, average loss 0.2301 \n",
            "\n",
            "weights: 0.4969 0.9341 0.3537 -0.0139\n",
            "[[0, 0, 0], 0]:0.4597, error=-0.4597, loss=0.1057, grad=0.3626 0.0000 0.0000 0.0000\n",
            "weights: 0.4933 0.9341 0.3537 -0.0139\n",
            "[[0, 0, 1], 1]:0.4458, error=0.5542, loss=0.1536, grad=-0.4441 -0.0000 -0.0000 -0.4441\n",
            "weights: 0.4977 0.9341 0.3537 -0.0095\n",
            "[[0, 1, 0], 1]:0.6918, error=0.3082, loss=0.0475, grad=-0.1607 -0.0000 -0.1607 -0.0000\n",
            "weights: 0.4993 0.9341 0.3553 -0.0095\n",
            "[[1, 0, 0], 1]:0.8924, error=0.1076, loss=0.0058, grad=-0.0219 -0.0219 -0.0000 -0.0000\n",
            "weights: 0.4996 0.9343 0.3553 -0.0095\n",
            "[[0, 1, 1], 0]:0.6887, error=-0.6887, loss=0.2371, grad=0.3621 0.0000 0.3621 0.3621\n",
            "weights: 0.4959 0.9343 0.3517 -0.0131\n",
            "[[1, 0, 1], 0]:0.8890, error=-0.8890, loss=0.3952, grad=0.1864 0.1864 0.0000 0.1864\n",
            "weights: 0.4941 0.9324 0.3517 -0.0150\n",
            "[[1, 1, 0], 0]:0.9445, error=-0.9445, loss=0.4460, grad=0.1019 0.1019 0.1019 0.0000\n",
            "weights: 0.4931 0.9314 0.3507 -0.0150\n",
            "[[1, 1, 1], 0]:0.9425, error=-0.9425, loss=0.4442, grad=0.1052 0.1052 0.1052 0.1052\n",
            "epoch12, average loss 0.2294 \n",
            "\n",
            "weights: 0.4920 0.9304 0.3496 -0.0160\n",
            "[[0, 0, 0], 0]:0.4558, error=-0.4558, loss=0.1039, grad=0.3611 0.0000 0.0000 0.0000\n",
            "weights: 0.4884 0.9304 0.3496 -0.0160\n",
            "[[0, 0, 1], 1]:0.4401, error=0.5599, loss=0.1567, grad=-0.4514 -0.0000 -0.0000 -0.4514\n",
            "weights: 0.4929 0.9304 0.3496 -0.0115\n",
            "[[0, 1, 0], 1]:0.6872, error=0.3128, loss=0.0489, grad=-0.1651 -0.0000 -0.1651 -0.0000\n",
            "weights: 0.4946 0.9304 0.3513 -0.0115\n",
            "[[1, 0, 0], 1]:0.8906, error=0.1094, loss=0.0060, grad=-0.0226 -0.0226 -0.0000 -0.0000\n",
            "weights: 0.4948 0.9306 0.3513 -0.0115\n",
            "[[0, 1, 1], 0]:0.6829, error=-0.6829, loss=0.2332, grad=0.3644 0.0000 0.3644 0.3644\n",
            "weights: 0.4911 0.9306 0.3476 -0.0151\n",
            "[[1, 0, 1], 0]:0.8868, error=-0.8868, loss=0.3932, grad=0.1894 0.1894 0.0000 0.1894\n",
            "weights: 0.4893 0.9287 0.3476 -0.0170\n",
            "[[1, 1, 0], 0]:0.9431, error=-0.9431, loss=0.4447, grad=0.1042 0.1042 0.1042 0.0000\n",
            "weights: 0.4882 0.9277 0.3466 -0.0170\n",
            "[[1, 1, 1], 0]:0.9409, error=-0.9409, loss=0.4426, grad=0.1080 0.1080 0.1080 0.1080\n",
            "epoch13, average loss 0.2287 \n",
            "\n",
            "weights: 0.4871 0.9266 0.3455 -0.0181\n",
            "[[0, 0, 0], 0]:0.4519, error=-0.4519, loss=0.1021, grad=0.3596 0.0000 0.0000 0.0000\n",
            "weights: 0.4835 0.9266 0.3455 -0.0181\n",
            "[[0, 0, 1], 1]:0.4345, error=0.5655, loss=0.1599, grad=-0.4587 -0.0000 -0.0000 -0.4587\n",
            "weights: 0.4881 0.9266 0.3455 -0.0135\n",
            "[[0, 1, 0], 1]:0.6824, error=0.3176, loss=0.0504, grad=-0.1697 -0.0000 -0.1697 -0.0000\n",
            "weights: 0.4898 0.9266 0.3472 -0.0135\n",
            "[[1, 0, 0], 1]:0.8888, error=0.1112, loss=0.0062, grad=-0.0233 -0.0233 -0.0000 -0.0000\n",
            "weights: 0.4901 0.9268 0.3472 -0.0135\n",
            "[[0, 1, 1], 0]:0.6771, error=-0.6771, loss=0.2292, grad=0.3667 0.0000 0.3667 0.3667\n",
            "weights: 0.4864 0.9268 0.3436 -0.0172\n",
            "[[1, 0, 1], 0]:0.8845, error=-0.8845, loss=0.3912, grad=0.1925 0.1925 0.0000 0.1925\n",
            "weights: 0.4845 0.9249 0.3436 -0.0191\n",
            "[[1, 1, 0], 0]:0.9417, error=-0.9417, loss=0.4434, grad=0.1066 0.1066 0.1066 0.0000\n",
            "weights: 0.4834 0.9238 0.3425 -0.0191\n",
            "[[1, 1, 1], 0]:0.9391, error=-0.9391, loss=0.4410, grad=0.1109 0.1109 0.1109 0.1109\n",
            "epoch14, average loss 0.2279 \n",
            "\n",
            "weights: 0.4823 0.9227 0.3414 -0.0202\n",
            "[[0, 0, 0], 0]:0.4481, error=-0.4481, loss=0.1004, grad=0.3581 0.0000 0.0000 0.0000\n",
            "weights: 0.4787 0.9227 0.3414 -0.0202\n",
            "[[0, 0, 1], 1]:0.4288, error=0.5712, loss=0.1631, grad=-0.4661 -0.0000 -0.0000 -0.4661\n",
            "weights: 0.4834 0.9227 0.3414 -0.0156\n",
            "[[0, 1, 0], 1]:0.6776, error=0.3224, loss=0.0520, grad=-0.1743 -0.0000 -0.1743 -0.0000\n",
            "weights: 0.4851 0.9227 0.3431 -0.0156\n",
            "[[1, 0, 0], 1]:0.8870, error=0.1130, loss=0.0064, grad=-0.0241 -0.0241 -0.0000 -0.0000\n",
            "weights: 0.4853 0.9230 0.3431 -0.0156\n",
            "[[0, 1, 1], 0]:0.6712, error=-0.6712, loss=0.2252, grad=0.3688 0.0000 0.3688 0.3688\n",
            "weights: 0.4817 0.9230 0.3394 -0.0193\n",
            "[[1, 0, 1], 0]:0.8821, error=-0.8821, loss=0.3891, grad=0.1957 0.1957 0.0000 0.1957\n",
            "weights: 0.4797 0.9210 0.3394 -0.0212\n",
            "[[1, 1, 0], 0]:0.9402, error=-0.9402, loss=0.4420, grad=0.1090 0.1090 0.1090 0.0000\n",
            "weights: 0.4786 0.9199 0.3383 -0.0212\n",
            "[[1, 1, 1], 0]:0.9373, error=-0.9373, loss=0.4393, grad=0.1138 0.1138 0.1138 0.1138\n",
            "epoch15, average loss 0.2272 \n",
            "\n",
            "weights: 0.4775 0.9188 0.3372 -0.0223\n",
            "[[0, 0, 0], 0]:0.4442, error=-0.4442, loss=0.0987, grad=0.3566 0.0000 0.0000 0.0000\n",
            "weights: 0.4739 0.9188 0.3372 -0.0223\n",
            "[[0, 0, 1], 1]:0.4232, error=0.5768, loss=0.1664, grad=-0.4735 -0.0000 -0.0000 -0.4735\n",
            "weights: 0.4786 0.9188 0.3372 -0.0176\n",
            "[[0, 1, 0], 1]:0.6728, error=0.3272, loss=0.0535, grad=-0.1791 -0.0000 -0.1791 -0.0000\n",
            "weights: 0.4804 0.9188 0.3390 -0.0176\n",
            "[[1, 0, 0], 1]:0.8852, error=0.1148, loss=0.0066, grad=-0.0249 -0.0249 -0.0000 -0.0000\n",
            "weights: 0.4807 0.9190 0.3390 -0.0176\n",
            "[[0, 1, 1], 0]:0.6652, error=-0.6652, loss=0.2212, grad=0.3709 0.0000 0.3709 0.3709\n",
            "weights: 0.4770 0.9190 0.3353 -0.0213\n",
            "[[1, 0, 1], 0]:0.8798, error=-0.8798, loss=0.3870, grad=0.1989 0.1989 0.0000 0.1989\n",
            "weights: 0.4750 0.9170 0.3353 -0.0233\n",
            "[[1, 1, 0], 0]:0.9387, error=-0.9387, loss=0.4406, grad=0.1115 0.1115 0.1115 0.0000\n",
            "weights: 0.4739 0.9159 0.3342 -0.0233\n",
            "[[1, 1, 1], 0]:0.9355, error=-0.9355, loss=0.4376, grad=0.1168 0.1168 0.1168 0.1168\n",
            "epoch16, average loss 0.2264 \n",
            "\n",
            "weights: 0.4727 0.9147 0.3330 -0.0245\n",
            "[[0, 0, 0], 0]:0.4404, error=-0.4404, loss=0.0970, grad=0.3550 0.0000 0.0000 0.0000\n",
            "weights: 0.4692 0.9147 0.3330 -0.0245\n",
            "[[0, 0, 1], 1]:0.4175, error=0.5825, loss=0.1696, grad=-0.4809 -0.0000 -0.0000 -0.4809\n",
            "weights: 0.4740 0.9147 0.3330 -0.0197\n",
            "[[0, 1, 0], 1]:0.6679, error=0.3321, loss=0.0551, grad=-0.1839 -0.0000 -0.1839 -0.0000\n",
            "weights: 0.4758 0.9147 0.3348 -0.0197\n",
            "[[1, 0, 0], 1]:0.8833, error=0.1167, loss=0.0068, grad=-0.0257 -0.0257 -0.0000 -0.0000\n",
            "weights: 0.4761 0.9150 0.3348 -0.0197\n",
            "[[0, 1, 1], 0]:0.6591, error=-0.6591, loss=0.2172, grad=0.3728 0.0000 0.3728 0.3728\n",
            "weights: 0.4723 0.9150 0.3311 -0.0234\n",
            "[[1, 0, 1], 0]:0.8773, error=-0.8773, loss=0.3848, grad=0.2021 0.2021 0.0000 0.2021\n",
            "weights: 0.4703 0.9130 0.3311 -0.0254\n",
            "[[1, 1, 0], 0]:0.9372, error=-0.9372, loss=0.4392, grad=0.1140 0.1140 0.1140 0.0000\n",
            "weights: 0.4692 0.9118 0.3300 -0.0254\n",
            "[[1, 1, 1], 0]:0.9336, error=-0.9336, loss=0.4358, grad=0.1199 0.1199 0.1199 0.1199\n",
            "epoch17, average loss 0.2257 \n",
            "\n",
            "weights: 0.4680 0.9106 0.3288 -0.0266\n",
            "[[0, 0, 0], 0]:0.4366, error=-0.4366, loss=0.0953, grad=0.3534 0.0000 0.0000 0.0000\n",
            "weights: 0.4644 0.9106 0.3288 -0.0266\n",
            "[[0, 0, 1], 1]:0.4118, error=0.5882, loss=0.1730, grad=-0.4884 -0.0000 -0.0000 -0.4884\n",
            "weights: 0.4693 0.9106 0.3288 -0.0217\n",
            "[[0, 1, 0], 1]:0.6630, error=0.3370, loss=0.0568, grad=-0.1889 -0.0000 -0.1889 -0.0000\n",
            "weights: 0.4712 0.9106 0.3307 -0.0217\n",
            "[[1, 0, 0], 1]:0.8814, error=0.1186, loss=0.0070, grad=-0.0265 -0.0265 -0.0000 -0.0000\n",
            "weights: 0.4715 0.9109 0.3307 -0.0217\n",
            "[[0, 1, 1], 0]:0.6529, error=-0.6529, loss=0.2132, grad=0.3746 0.0000 0.3746 0.3746\n",
            "weights: 0.4677 0.9109 0.3269 -0.0255\n",
            "[[1, 0, 1], 0]:0.8748, error=-0.8748, loss=0.3826, grad=0.2053 0.2053 0.0000 0.2053\n",
            "weights: 0.4657 0.9089 0.3269 -0.0275\n",
            "[[1, 1, 0], 0]:0.9356, error=-0.9356, loss=0.4377, grad=0.1166 0.1166 0.1166 0.0000\n",
            "weights: 0.4645 0.9077 0.3258 -0.0275\n",
            "[[1, 1, 1], 0]:0.9316, error=-0.9316, loss=0.4339, grad=0.1231 0.1231 0.1231 0.1231\n",
            "epoch18, average loss 0.2249 \n",
            "\n",
            "weights: 0.4633 0.9065 0.3245 -0.0288\n",
            "[[0, 0, 0], 0]:0.4328, error=-0.4328, loss=0.0936, grad=0.3517 0.0000 0.0000 0.0000\n",
            "weights: 0.4598 0.9065 0.3245 -0.0288\n",
            "[[0, 0, 1], 1]:0.4062, error=0.5938, loss=0.1763, grad=-0.4959 -0.0000 -0.0000 -0.4959\n",
            "weights: 0.4647 0.9065 0.3245 -0.0238\n",
            "[[0, 1, 0], 1]:0.6580, error=0.3420, loss=0.0585, grad=-0.1939 -0.0000 -0.1939 -0.0000\n",
            "weights: 0.4667 0.9065 0.3265 -0.0238\n",
            "[[1, 0, 0], 1]:0.8794, error=0.1206, loss=0.0073, grad=-0.0273 -0.0273 -0.0000 -0.0000\n",
            "weights: 0.4669 0.9067 0.3265 -0.0238\n",
            "[[0, 1, 1], 0]:0.6467, error=-0.6467, loss=0.2091, grad=0.3762 0.0000 0.3762 0.3762\n",
            "weights: 0.4632 0.9067 0.3227 -0.0276\n",
            "[[1, 0, 1], 0]:0.8722, error=-0.8722, loss=0.3804, grad=0.2086 0.2086 0.0000 0.2086\n",
            "weights: 0.4611 0.9046 0.3227 -0.0297\n",
            "[[1, 1, 0], 0]:0.9339, error=-0.9339, loss=0.4361, grad=0.1193 0.1193 0.1193 0.0000\n",
            "weights: 0.4599 0.9034 0.3215 -0.0297\n",
            "[[1, 1, 1], 0]:0.9296, error=-0.9296, loss=0.4320, grad=0.1263 0.1263 0.1263 0.1263\n",
            "epoch19, average loss 0.2242 \n",
            "\n",
            "weights: 0.4586 0.9022 0.3202 -0.0309\n",
            "[[0, 0, 0], 0]:0.4290, error=-0.4290, loss=0.0920, grad=0.3500 0.0000 0.0000 0.0000\n",
            "weights: 0.4551 0.9022 0.3202 -0.0309\n",
            "[[0, 0, 1], 1]:0.4005, error=0.5995, loss=0.1797, grad=-0.5034 -0.0000 -0.0000 -0.5034\n",
            "weights: 0.4602 0.9022 0.3202 -0.0259\n",
            "[[0, 1, 0], 1]:0.6529, error=0.3471, loss=0.0602, grad=-0.1991 -0.0000 -0.1991 -0.0000\n",
            "weights: 0.4622 0.9022 0.3222 -0.0259\n",
            "[[1, 0, 0], 1]:0.8774, error=0.1226, loss=0.0075, grad=-0.0282 -0.0282 -0.0000 -0.0000\n",
            "weights: 0.4624 0.9025 0.3222 -0.0259\n",
            "[[0, 1, 1], 0]:0.6404, error=-0.6404, loss=0.2050, grad=0.3778 0.0000 0.3778 0.3778\n",
            "weights: 0.4587 0.9025 0.3185 -0.0297\n",
            "[[1, 0, 1], 0]:0.8696, error=-0.8696, loss=0.3781, grad=0.2120 0.2120 0.0000 0.2120\n",
            "weights: 0.4565 0.9003 0.3185 -0.0318\n",
            "[[1, 1, 0], 0]:0.9323, error=-0.9323, loss=0.4345, grad=0.1220 0.1220 0.1220 0.0000\n",
            "weights: 0.4553 0.8991 0.3172 -0.0318\n",
            "[[1, 1, 1], 0]:0.9275, error=-0.9275, loss=0.4301, grad=0.1297 0.1297 0.1297 0.1297\n",
            "epoch20, average loss 0.2234 \n",
            "\n",
            "weights: 0.4540 0.8978 0.3159 -0.0331\n",
            "[[0, 0, 0], 0]:0.4252, error=-0.4252, loss=0.0904, grad=0.3483 0.0000 0.0000 0.0000\n",
            "weights: 0.4505 0.8978 0.3159 -0.0331\n",
            "[[0, 0, 1], 1]:0.3948, error=0.6052, loss=0.1831, grad=-0.5109 -0.0000 -0.0000 -0.5109\n",
            "weights: 0.4556 0.8978 0.3159 -0.0280\n",
            "[[0, 1, 0], 1]:0.6479, error=0.3521, loss=0.0620, grad=-0.2043 -0.0000 -0.2043 -0.0000\n",
            "weights: 0.4577 0.8978 0.3180 -0.0280\n",
            "[[1, 0, 0], 1]:0.8753, error=0.1247, loss=0.0078, grad=-0.0291 -0.0291 -0.0000 -0.0000\n",
            "weights: 0.4580 0.8981 0.3180 -0.0280\n",
            "[[0, 1, 1], 0]:0.6340, error=-0.6340, loss=0.2009, grad=0.3792 0.0000 0.3792 0.3792\n",
            "weights: 0.4542 0.8981 0.3142 -0.0318\n",
            "[[1, 0, 1], 0]:0.8669, error=-0.8669, loss=0.3758, grad=0.2154 0.2154 0.0000 0.2154\n",
            "weights: 0.4520 0.8960 0.3142 -0.0339\n",
            "[[1, 1, 0], 0]:0.9305, error=-0.9305, loss=0.4329, grad=0.1248 0.1248 0.1248 0.0000\n",
            "weights: 0.4508 0.8947 0.3129 -0.0339\n",
            "[[1, 1, 1], 0]:0.9253, error=-0.9253, loss=0.4281, grad=0.1331 0.1331 0.1331 0.1331\n",
            "epoch21, average loss 0.2226 \n",
            "\n",
            "weights: 0.4495 0.8934 0.3116 -0.0352\n",
            "[[0, 0, 0], 0]:0.4215, error=-0.4215, loss=0.0888, grad=0.3466 0.0000 0.0000 0.0000\n",
            "weights: 0.4460 0.8934 0.3116 -0.0352\n",
            "[[0, 0, 1], 1]:0.3891, error=0.6109, loss=0.1866, grad=-0.5184 -0.0000 -0.0000 -0.5184\n",
            "weights: 0.4512 0.8934 0.3116 -0.0301\n",
            "[[0, 1, 0], 1]:0.6427, error=0.3573, loss=0.0638, grad=-0.2097 -0.0000 -0.2097 -0.0000\n",
            "weights: 0.4533 0.8934 0.3137 -0.0301\n",
            "[[1, 0, 0], 1]:0.8733, error=0.1267, loss=0.0080, grad=-0.0301 -0.0301 -0.0000 -0.0000\n",
            "weights: 0.4536 0.8937 0.3137 -0.0301\n",
            "[[0, 1, 1], 0]:0.6275, error=-0.6275, loss=0.1969, grad=0.3804 0.0000 0.3804 0.3804\n",
            "weights: 0.4498 0.8937 0.3099 -0.0339\n",
            "[[1, 0, 1], 0]:0.8642, error=-0.8642, loss=0.3734, grad=0.2188 0.2188 0.0000 0.2188\n",
            "weights: 0.4476 0.8915 0.3099 -0.0361\n",
            "[[1, 1, 0], 0]:0.9287, error=-0.9287, loss=0.4313, grad=0.1277 0.1277 0.1277 0.0000\n",
            "weights: 0.4463 0.8902 0.3086 -0.0361\n",
            "[[1, 1, 1], 0]:0.9230, error=-0.9230, loss=0.4260, grad=0.1366 0.1366 0.1366 0.1366\n",
            "epoch22, average loss 0.2218 \n",
            "\n",
            "weights: 0.4449 0.8889 0.3073 -0.0374\n",
            "[[0, 0, 0], 0]:0.4177, error=-0.4177, loss=0.0872, grad=0.3448 0.0000 0.0000 0.0000\n",
            "weights: 0.4415 0.8889 0.3073 -0.0374\n",
            "[[0, 0, 1], 1]:0.3834, error=0.6166, loss=0.1901, grad=-0.5259 -0.0000 -0.0000 -0.5259\n",
            "weights: 0.4467 0.8889 0.3073 -0.0322\n",
            "[[0, 1, 0], 1]:0.6375, error=0.3625, loss=0.0657, grad=-0.2151 -0.0000 -0.2151 -0.0000\n",
            "weights: 0.4489 0.8889 0.3094 -0.0322\n",
            "[[1, 0, 0], 1]:0.8711, error=0.1289, loss=0.0083, grad=-0.0311 -0.0311 -0.0000 -0.0000\n",
            "weights: 0.4492 0.8892 0.3094 -0.0322\n",
            "[[0, 1, 1], 0]:0.6209, error=-0.6209, loss=0.1928, grad=0.3815 0.0000 0.3815 0.3815\n",
            "weights: 0.4454 0.8892 0.3056 -0.0360\n",
            "[[1, 0, 1], 0]:0.8614, error=-0.8614, loss=0.3710, grad=0.2223 0.2223 0.0000 0.2223\n",
            "weights: 0.4432 0.8869 0.3056 -0.0382\n",
            "[[1, 1, 0], 0]:0.9269, error=-0.9269, loss=0.4295, grad=0.1306 0.1306 0.1306 0.0000\n",
            "weights: 0.4419 0.8856 0.3043 -0.0382\n",
            "[[1, 1, 1], 0]:0.9207, error=-0.9207, loss=0.4238, grad=0.1402 0.1402 0.1402 0.1402\n",
            "epoch23, average loss 0.2211 \n",
            "\n",
            "weights: 0.4405 0.8842 0.3029 -0.0396\n",
            "[[0, 0, 0], 0]:0.4140, error=-0.4140, loss=0.0857, grad=0.3431 0.0000 0.0000 0.0000\n",
            "weights: 0.4370 0.8842 0.3029 -0.0396\n",
            "[[0, 0, 1], 1]:0.3778, error=0.6222, loss=0.1936, grad=-0.5335 -0.0000 -0.0000 -0.5335\n",
            "weights: 0.4424 0.8842 0.3029 -0.0343\n",
            "[[0, 1, 0], 1]:0.6323, error=0.3677, loss=0.0676, grad=-0.2207 -0.0000 -0.2207 -0.0000\n",
            "weights: 0.4446 0.8842 0.3051 -0.0343\n",
            "[[1, 0, 0], 1]:0.8690, error=0.1310, loss=0.0086, grad=-0.0321 -0.0321 -0.0000 -0.0000\n",
            "weights: 0.4449 0.8846 0.3051 -0.0343\n",
            "[[0, 1, 1], 0]:0.6143, error=-0.6143, loss=0.1887, grad=0.3825 0.0000 0.3825 0.3825\n",
            "weights: 0.4411 0.8846 0.3013 -0.0381\n",
            "[[1, 0, 1], 0]:0.8585, error=-0.8585, loss=0.3685, grad=0.2258 0.2258 0.0000 0.2258\n",
            "weights: 0.4388 0.8823 0.3013 -0.0403\n",
            "[[1, 1, 0], 0]:0.9250, error=-0.9250, loss=0.4278, grad=0.1336 0.1336 0.1336 0.0000\n",
            "weights: 0.4375 0.8810 0.2999 -0.0403\n",
            "[[1, 1, 1], 0]:0.9183, error=-0.9183, loss=0.4216, grad=0.1439 0.1439 0.1439 0.1439\n",
            "epoch24, average loss 0.2203 \n",
            "\n",
            "weights: 0.4360 0.8795 0.2985 -0.0418\n",
            "[[0, 0, 0], 0]:0.4104, error=-0.4104, loss=0.0842, grad=0.3413 0.0000 0.0000 0.0000\n",
            "weights: 0.4326 0.8795 0.2985 -0.0418\n",
            "[[0, 0, 1], 1]:0.3721, error=0.6279, loss=0.1971, grad=-0.5410 -0.0000 -0.0000 -0.5410\n",
            "weights: 0.4380 0.8795 0.2985 -0.0364\n",
            "[[0, 1, 0], 1]:0.6270, error=0.3730, loss=0.0695, grad=-0.2263 -0.0000 -0.2263 -0.0000\n",
            "weights: 0.4403 0.8795 0.3008 -0.0364\n",
            "[[1, 0, 0], 1]:0.8667, error=0.1333, loss=0.0089, grad=-0.0332 -0.0332 -0.0000 -0.0000\n",
            "weights: 0.4406 0.8799 0.3008 -0.0364\n",
            "[[0, 1, 1], 0]:0.6075, error=-0.6075, loss=0.1846, grad=0.3833 0.0000 0.3833 0.3833\n",
            "weights: 0.4368 0.8799 0.2969 -0.0402\n",
            "[[1, 0, 1], 0]:0.8555, error=-0.8555, loss=0.3660, grad=0.2293 0.2293 0.0000 0.2293\n",
            "weights: 0.4345 0.8776 0.2969 -0.0425\n",
            "[[1, 1, 0], 0]:0.9230, error=-0.9230, loss=0.4260, grad=0.1367 0.1367 0.1367 0.0000\n",
            "weights: 0.4331 0.8762 0.2956 -0.0425\n",
            "[[1, 1, 1], 0]:0.9158, error=-0.9158, loss=0.4194, grad=0.1477 0.1477 0.1477 0.1477\n",
            "epoch25, average loss 0.2195 \n",
            "\n",
            "weights: 0.4317 0.8747 0.2941 -0.0440\n",
            "[[0, 0, 0], 0]:0.4067, error=-0.4067, loss=0.0827, grad=0.3394 0.0000 0.0000 0.0000\n",
            "weights: 0.4283 0.8747 0.2941 -0.0440\n",
            "[[0, 0, 1], 1]:0.3664, error=0.6336, loss=0.2007, grad=-0.5485 -0.0000 -0.0000 -0.5485\n",
            "weights: 0.4337 0.8747 0.2941 -0.0385\n",
            "[[0, 1, 0], 1]:0.6217, error=0.3783, loss=0.0715, grad=-0.2320 -0.0000 -0.2320 -0.0000\n",
            "weights: 0.4361 0.8747 0.2964 -0.0385\n",
            "[[1, 0, 0], 1]:0.8645, error=0.1355, loss=0.0092, grad=-0.0342 -0.0342 -0.0000 -0.0000\n",
            "weights: 0.4364 0.8751 0.2964 -0.0385\n",
            "[[0, 1, 1], 0]:0.6008, error=-0.6008, loss=0.1805, grad=0.3839 0.0000 0.3839 0.3839\n",
            "weights: 0.4326 0.8751 0.2926 -0.0423\n",
            "[[1, 0, 1], 0]:0.8525, error=-0.8525, loss=0.3634, grad=0.2329 0.2329 0.0000 0.2329\n",
            "weights: 0.4302 0.8727 0.2926 -0.0447\n",
            "[[1, 1, 0], 0]:0.9210, error=-0.9210, loss=0.4241, grad=0.1398 0.1398 0.1398 0.0000\n",
            "weights: 0.4288 0.8713 0.2912 -0.0447\n",
            "[[1, 1, 1], 0]:0.9132, error=-0.9132, loss=0.4170, grad=0.1516 0.1516 0.1516 0.1516\n",
            "epoch26, average loss 0.2186 \n",
            "\n",
            "weights: 0.4273 0.8698 0.2897 -0.0462\n",
            "[[0, 0, 0], 0]:0.4031, error=-0.4031, loss=0.0812, grad=0.3376 0.0000 0.0000 0.0000\n",
            "weights: 0.4240 0.8698 0.2897 -0.0462\n",
            "[[0, 0, 1], 1]:0.3608, error=0.6392, loss=0.2043, grad=-0.5560 -0.0000 -0.0000 -0.5560\n",
            "weights: 0.4295 0.8698 0.2897 -0.0406\n",
            "[[0, 1, 0], 1]:0.6164, error=0.3836, loss=0.0736, grad=-0.2379 -0.0000 -0.2379 -0.0000\n",
            "weights: 0.4319 0.8698 0.2920 -0.0406\n",
            "[[1, 0, 0], 1]:0.8622, error=0.1378, loss=0.0095, grad=-0.0354 -0.0354 -0.0000 -0.0000\n",
            "weights: 0.4322 0.8702 0.2920 -0.0406\n",
            "[[0, 1, 1], 0]:0.5939, error=-0.5939, loss=0.1764, grad=0.3844 0.0000 0.3844 0.3844\n",
            "weights: 0.4284 0.8702 0.2882 -0.0445\n",
            "[[1, 0, 1], 0]:0.8494, error=-0.8494, loss=0.3608, grad=0.2365 0.2365 0.0000 0.2365\n",
            "weights: 0.4260 0.8678 0.2882 -0.0468\n",
            "[[1, 1, 0], 0]:0.9189, error=-0.9189, loss=0.4222, grad=0.1430 0.1430 0.1430 0.0000\n",
            "weights: 0.4246 0.8664 0.2868 -0.0468\n",
            "[[1, 1, 1], 0]:0.9106, error=-0.9106, loss=0.4146, grad=0.1556 0.1556 0.1556 0.1556\n",
            "epoch27, average loss 0.2178 \n",
            "\n",
            "weights: 0.4231 0.8648 0.2852 -0.0484\n",
            "[[0, 0, 0], 0]:0.3995, error=-0.3995, loss=0.0798, grad=0.3357 0.0000 0.0000 0.0000\n",
            "weights: 0.4197 0.8648 0.2852 -0.0484\n",
            "[[0, 0, 1], 1]:0.3551, error=0.6449, loss=0.2079, grad=-0.5635 -0.0000 -0.0000 -0.5635\n",
            "weights: 0.4253 0.8648 0.2852 -0.0427\n",
            "[[0, 1, 0], 1]:0.6110, error=0.3890, loss=0.0757, grad=-0.2438 -0.0000 -0.2438 -0.0000\n",
            "weights: 0.4278 0.8648 0.2876 -0.0427\n",
            "[[1, 0, 0], 1]:0.8598, error=0.1402, loss=0.0098, grad=-0.0366 -0.0366 -0.0000 -0.0000\n",
            "weights: 0.4281 0.8652 0.2876 -0.0427\n",
            "[[0, 1, 1], 0]:0.5870, error=-0.5870, loss=0.1723, grad=0.3847 0.0000 0.3847 0.3847\n",
            "weights: 0.4243 0.8652 0.2838 -0.0466\n",
            "[[1, 0, 1], 0]:0.8463, error=-0.8463, loss=0.3581, grad=0.2402 0.2402 0.0000 0.2402\n",
            "weights: 0.4219 0.8628 0.2838 -0.0490\n",
            "[[1, 1, 0], 0]:0.9168, error=-0.9168, loss=0.4202, grad=0.1462 0.1462 0.1462 0.0000\n",
            "weights: 0.4204 0.8613 0.2823 -0.0490\n",
            "[[1, 1, 1], 0]:0.9078, error=-0.9078, loss=0.4121, grad=0.1596 0.1596 0.1596 0.1596\n",
            "epoch28, average loss 0.2170 \n",
            "\n",
            "weights: 0.4188 0.8597 0.2807 -0.0506\n",
            "[[0, 0, 0], 0]:0.3959, error=-0.3959, loss=0.0784, grad=0.3339 0.0000 0.0000 0.0000\n",
            "weights: 0.4155 0.8597 0.2807 -0.0506\n",
            "[[0, 0, 1], 1]:0.3495, error=0.6505, loss=0.2116, grad=-0.5710 -0.0000 -0.0000 -0.5710\n",
            "weights: 0.4212 0.8597 0.2807 -0.0449\n",
            "[[0, 1, 0], 1]:0.6056, error=0.3944, loss=0.0778, grad=-0.2498 -0.0000 -0.2498 -0.0000\n",
            "weights: 0.4237 0.8597 0.2832 -0.0449\n",
            "[[1, 0, 0], 1]:0.8574, error=0.1426, loss=0.0102, grad=-0.0378 -0.0378 -0.0000 -0.0000\n",
            "weights: 0.4241 0.8601 0.2832 -0.0449\n",
            "[[0, 1, 1], 0]:0.5800, error=-0.5800, loss=0.1682, grad=0.3849 0.0000 0.3849 0.3849\n",
            "weights: 0.4202 0.8601 0.2794 -0.0487\n",
            "[[1, 0, 1], 0]:0.8430, error=-0.8430, loss=0.3554, grad=0.2439 0.2439 0.0000 0.2439\n",
            "weights: 0.4178 0.8577 0.2794 -0.0512\n",
            "[[1, 1, 0], 0]:0.9146, error=-0.9146, loss=0.4182, grad=0.1496 0.1496 0.1496 0.0000\n",
            "weights: 0.4163 0.8562 0.2779 -0.0512\n",
            "[[1, 1, 1], 0]:0.9050, error=-0.9050, loss=0.4095, grad=0.1638 0.1638 0.1638 0.1638\n",
            "epoch29, average loss 0.2161 \n",
            "\n",
            "weights: 0.4147 0.8545 0.2762 -0.0528\n",
            "[[0, 0, 0], 0]:0.3924, error=-0.3924, loss=0.0770, grad=0.3320 0.0000 0.0000 0.0000\n",
            "weights: 0.4113 0.8545 0.2762 -0.0528\n",
            "[[0, 0, 1], 1]:0.3439, error=0.6561, loss=0.2152, grad=-0.5785 -0.0000 -0.0000 -0.5785\n",
            "weights: 0.4171 0.8545 0.2762 -0.0470\n",
            "[[0, 1, 0], 1]:0.6001, error=0.3999, loss=0.0799, grad=-0.2558 -0.0000 -0.2558 -0.0000\n",
            "weights: 0.4197 0.8545 0.2788 -0.0470\n",
            "[[1, 0, 0], 1]:0.8549, error=0.1451, loss=0.0105, grad=-0.0390 -0.0390 -0.0000 -0.0000\n",
            "weights: 0.4201 0.8549 0.2788 -0.0470\n",
            "[[0, 1, 1], 0]:0.5729, error=-0.5729, loss=0.1641, grad=0.3849 0.0000 0.3849 0.3849\n",
            "weights: 0.4162 0.8549 0.2750 -0.0509\n",
            "[[1, 0, 1], 0]:0.8397, error=-0.8397, loss=0.3526, grad=0.2476 0.2476 0.0000 0.2476\n",
            "weights: 0.4137 0.8524 0.2750 -0.0533\n",
            "[[1, 1, 0], 0]:0.9123, error=-0.9123, loss=0.4162, grad=0.1530 0.1530 0.1530 0.0000\n",
            "weights: 0.4122 0.8509 0.2734 -0.0533\n",
            "[[1, 1, 1], 0]:0.9021, error=-0.9021, loss=0.4069, grad=0.1680 0.1680 0.1680 0.1680\n",
            "epoch30, average loss 0.2153 \n",
            "\n",
            "weights: 0.4105 0.8492 0.2717 -0.0550\n",
            "[[0, 0, 0], 0]:0.3889, error=-0.3889, loss=0.0756, grad=0.3301 0.0000 0.0000 0.0000\n",
            "weights: 0.4072 0.8492 0.2717 -0.0550\n",
            "[[0, 0, 1], 1]:0.3383, error=0.6617, loss=0.2189, grad=-0.5859 -0.0000 -0.0000 -0.5859\n",
            "weights: 0.4131 0.8492 0.2717 -0.0492\n",
            "[[0, 1, 0], 1]:0.5947, error=0.4053, loss=0.0822, grad=-0.2620 -0.0000 -0.2620 -0.0000\n",
            "weights: 0.4157 0.8492 0.2744 -0.0492\n",
            "[[1, 0, 0], 1]:0.8524, error=0.1476, loss=0.0109, grad=-0.0403 -0.0403 -0.0000 -0.0000\n",
            "weights: 0.4161 0.8496 0.2744 -0.0492\n",
            "[[0, 1, 1], 0]:0.5658, error=-0.5658, loss=0.1601, grad=0.3847 0.0000 0.3847 0.3847\n",
            "weights: 0.4123 0.8496 0.2705 -0.0530\n",
            "[[1, 0, 1], 0]:0.8363, error=-0.8363, loss=0.3497, grad=0.2513 0.2513 0.0000 0.2513\n",
            "weights: 0.4098 0.8471 0.2705 -0.0555\n",
            "[[1, 1, 0], 0]:0.9100, error=-0.9100, loss=0.4140, grad=0.1565 0.1565 0.1565 0.0000\n",
            "weights: 0.4082 0.8456 0.2690 -0.0555\n",
            "[[1, 1, 1], 0]:0.8990, error=-0.8990, loss=0.4041, grad=0.1724 0.1724 0.1724 0.1724\n",
            "epoch31, average loss 0.2144 \n",
            "\n",
            "weights: 0.4065 0.8438 0.2672 -0.0573\n",
            "[[0, 0, 0], 0]:0.3855, error=-0.3855, loss=0.0743, grad=0.3282 0.0000 0.0000 0.0000\n",
            "weights: 0.4032 0.8438 0.2672 -0.0573\n",
            "[[0, 0, 1], 1]:0.3328, error=0.6672, loss=0.2226, grad=-0.5934 -0.0000 -0.0000 -0.5934\n",
            "weights: 0.4091 0.8438 0.2672 -0.0513\n",
            "[[0, 1, 0], 1]:0.5891, error=0.4109, loss=0.0844, grad=-0.2683 -0.0000 -0.2683 -0.0000\n",
            "weights: 0.4118 0.8438 0.2699 -0.0513\n",
            "[[1, 0, 0], 1]:0.8499, error=0.1501, loss=0.0113, grad=-0.0417 -0.0417 -0.0000 -0.0000\n",
            "weights: 0.4122 0.8443 0.2699 -0.0513\n",
            "[[0, 1, 1], 0]:0.5586, error=-0.5586, loss=0.1560, grad=0.3843 0.0000 0.3843 0.3843\n",
            "weights: 0.4084 0.8443 0.2661 -0.0552\n",
            "[[1, 0, 1], 0]:0.8329, error=-0.8329, loss=0.3468, grad=0.2551 0.2551 0.0000 0.2551\n",
            "weights: 0.4058 0.8417 0.2661 -0.0577\n",
            "[[1, 1, 0], 0]:0.9076, error=-0.9076, loss=0.4118, grad=0.1600 0.1600 0.1600 0.0000\n",
            "weights: 0.4042 0.8401 0.2645 -0.0577\n",
            "[[1, 1, 1], 0]:0.8959, error=-0.8959, loss=0.4013, grad=0.1768 0.1768 0.1768 0.1768\n",
            "epoch32, average loss 0.2136 \n",
            "\n",
            "weights: 0.4025 0.8383 0.2627 -0.0595\n",
            "[[0, 0, 0], 0]:0.3820, error=-0.3820, loss=0.0730, grad=0.3263 0.0000 0.0000 0.0000\n",
            "weights: 0.3992 0.8383 0.2627 -0.0595\n",
            "[[0, 0, 1], 1]:0.3272, error=0.6728, loss=0.2263, grad=-0.6007 -0.0000 -0.0000 -0.6007\n",
            "weights: 0.4052 0.8383 0.2627 -0.0535\n",
            "[[0, 1, 0], 1]:0.5836, error=0.4164, loss=0.0867, grad=-0.2746 -0.0000 -0.2746 -0.0000\n",
            "weights: 0.4079 0.8383 0.2655 -0.0535\n",
            "[[1, 0, 0], 1]:0.8472, error=0.1528, loss=0.0117, grad=-0.0431 -0.0431 -0.0000 -0.0000\n",
            "weights: 0.4084 0.8388 0.2655 -0.0535\n",
            "[[0, 1, 1], 0]:0.5514, error=-0.5514, loss=0.1520, grad=0.3837 0.0000 0.3837 0.3837\n",
            "weights: 0.4045 0.8388 0.2616 -0.0573\n",
            "[[1, 0, 1], 0]:0.8293, error=-0.8293, loss=0.3439, grad=0.2589 0.2589 0.0000 0.2589\n",
            "weights: 0.4019 0.8362 0.2616 -0.0599\n",
            "[[1, 1, 0], 0]:0.9051, error=-0.9051, loss=0.4096, grad=0.1636 0.1636 0.1636 0.0000\n",
            "weights: 0.4003 0.8345 0.2600 -0.0599\n",
            "[[1, 1, 1], 0]:0.8927, error=-0.8927, loss=0.3984, grad=0.1813 0.1813 0.1813 0.1813\n",
            "epoch33, average loss 0.2127 \n",
            "\n",
            "weights: 0.3985 0.8327 0.2582 -0.0617\n",
            "[[0, 0, 0], 0]:0.3787, error=-0.3787, loss=0.0717, grad=0.3244 0.0000 0.0000 0.0000\n",
            "weights: 0.3953 0.8327 0.2582 -0.0617\n",
            "[[0, 0, 1], 1]:0.3217, error=0.6783, loss=0.2300, grad=-0.6081 -0.0000 -0.0000 -0.6081\n",
            "weights: 0.4013 0.8327 0.2582 -0.0556\n",
            "[[0, 1, 0], 1]:0.5780, error=0.4220, loss=0.0890, grad=-0.2810 -0.0000 -0.2810 -0.0000\n",
            "weights: 0.4041 0.8327 0.2610 -0.0556\n",
            "[[1, 0, 0], 1]:0.8446, error=0.1554, loss=0.0121, grad=-0.0446 -0.0446 -0.0000 -0.0000\n",
            "weights: 0.4046 0.8332 0.2610 -0.0556\n",
            "[[0, 1, 1], 0]:0.5441, error=-0.5441, loss=0.1480, grad=0.3830 0.0000 0.3830 0.3830\n",
            "weights: 0.4008 0.8332 0.2571 -0.0595\n",
            "[[1, 0, 1], 0]:0.8257, error=-0.8257, loss=0.3409, grad=0.2628 0.2628 0.0000 0.2628\n",
            "weights: 0.3981 0.8305 0.2571 -0.0621\n",
            "[[1, 1, 0], 0]:0.9026, error=-0.9026, loss=0.4073, grad=0.1673 0.1673 0.1673 0.0000\n",
            "weights: 0.3965 0.8289 0.2555 -0.0621\n",
            "[[1, 1, 1], 0]:0.8893, error=-0.8893, loss=0.3955, grad=0.1860 0.1860 0.1860 0.1860\n",
            "epoch34, average loss 0.2118 \n",
            "\n",
            "weights: 0.3946 0.8270 0.2536 -0.0640\n",
            "[[0, 0, 0], 0]:0.3753, error=-0.3753, loss=0.0704, grad=0.3224 0.0000 0.0000 0.0000\n",
            "weights: 0.3914 0.8270 0.2536 -0.0640\n",
            "[[0, 0, 1], 1]:0.3162, error=0.6838, loss=0.2338, grad=-0.6154 -0.0000 -0.0000 -0.6154\n",
            "weights: 0.3975 0.8270 0.2536 -0.0578\n",
            "[[0, 1, 0], 1]:0.5724, error=0.4276, loss=0.0914, grad=-0.2875 -0.0000 -0.2875 -0.0000\n",
            "weights: 0.4004 0.8270 0.2565 -0.0578\n",
            "[[1, 0, 0], 1]:0.8418, error=0.1582, loss=0.0125, grad=-0.0461 -0.0461 -0.0000 -0.0000\n",
            "weights: 0.4009 0.8275 0.2565 -0.0578\n",
            "[[0, 1, 1], 0]:0.5367, error=-0.5367, loss=0.1440, grad=0.3821 0.0000 0.3821 0.3821\n",
            "weights: 0.3970 0.8275 0.2527 -0.0616\n",
            "[[1, 0, 1], 0]:0.8220, error=-0.8220, loss=0.3378, grad=0.2666 0.2666 0.0000 0.2666\n",
            "weights: 0.3944 0.8248 0.2527 -0.0643\n",
            "[[1, 1, 0], 0]:0.8999, error=-0.8999, loss=0.4049, grad=0.1711 0.1711 0.1711 0.0000\n",
            "weights: 0.3927 0.8231 0.2510 -0.0643\n",
            "[[1, 1, 1], 0]:0.8859, error=-0.8859, loss=0.3924, grad=0.1907 0.1907 0.1907 0.1907\n",
            "epoch35, average loss 0.2109 \n",
            "\n",
            "weights: 0.3908 0.8212 0.2490 -0.0662\n",
            "[[0, 0, 0], 0]:0.3720, error=-0.3720, loss=0.0692, grad=0.3205 0.0000 0.0000 0.0000\n",
            "weights: 0.3876 0.8212 0.2490 -0.0662\n",
            "[[0, 0, 1], 1]:0.3107, error=0.6893, loss=0.2375, grad=-0.6227 -0.0000 -0.0000 -0.6227\n",
            "weights: 0.3938 0.8212 0.2490 -0.0600\n",
            "[[0, 1, 0], 1]:0.5668, error=0.4332, loss=0.0938, grad=-0.2940 -0.0000 -0.2940 -0.0000\n",
            "weights: 0.3967 0.8212 0.2520 -0.0600\n",
            "[[1, 0, 0], 1]:0.8390, error=0.1610, loss=0.0130, grad=-0.0476 -0.0476 -0.0000 -0.0000\n",
            "weights: 0.3972 0.8217 0.2520 -0.0600\n",
            "[[0, 1, 1], 0]:0.5293, error=-0.5293, loss=0.1401, grad=0.3810 0.0000 0.3810 0.3810\n",
            "weights: 0.3934 0.8217 0.2482 -0.0638\n",
            "[[1, 0, 1], 0]:0.8182, error=-0.8182, loss=0.3347, grad=0.2705 0.2705 0.0000 0.2705\n",
            "weights: 0.3907 0.8190 0.2482 -0.0665\n",
            "[[1, 1, 0], 0]:0.8972, error=-0.8972, loss=0.4025, grad=0.1749 0.1749 0.1749 0.0000\n",
            "weights: 0.3889 0.8172 0.2464 -0.0665\n",
            "[[1, 1, 1], 0]:0.8823, error=-0.8823, loss=0.3892, grad=0.1955 0.1955 0.1955 0.1955\n",
            "epoch36, average loss 0.2100 \n",
            "\n",
            "weights: 0.3870 0.8153 0.2445 -0.0684\n",
            "[[0, 0, 0], 0]:0.3688, error=-0.3688, loss=0.0680, grad=0.3186 0.0000 0.0000 0.0000\n",
            "weights: 0.3838 0.8153 0.2445 -0.0684\n",
            "[[0, 0, 1], 1]:0.3053, error=0.6947, loss=0.2413, grad=-0.6299 -0.0000 -0.0000 -0.6299\n",
            "weights: 0.3901 0.8153 0.2445 -0.0621\n",
            "[[0, 1, 0], 1]:0.5612, error=0.4388, loss=0.0963, grad=-0.3006 -0.0000 -0.3006 -0.0000\n",
            "weights: 0.3931 0.8153 0.2475 -0.0621\n",
            "[[1, 0, 0], 1]:0.8362, error=0.1638, loss=0.0134, grad=-0.0493 -0.0493 -0.0000 -0.0000\n",
            "weights: 0.3936 0.8158 0.2475 -0.0621\n",
            "[[0, 1, 1], 0]:0.5219, error=-0.5219, loss=0.1362, grad=0.3797 0.0000 0.3797 0.3797\n",
            "weights: 0.3898 0.8158 0.2437 -0.0659\n",
            "[[1, 0, 1], 0]:0.8143, error=-0.8143, loss=0.3315, grad=0.2744 0.2744 0.0000 0.2744\n",
            "weights: 0.3871 0.8130 0.2437 -0.0687\n",
            "[[1, 1, 0], 0]:0.8944, error=-0.8944, loss=0.4000, grad=0.1789 0.1789 0.1789 0.0000\n",
            "weights: 0.3853 0.8112 0.2419 -0.0687\n",
            "[[1, 1, 1], 0]:0.8786, error=-0.8786, loss=0.3860, grad=0.2003 0.2003 0.2003 0.2003\n",
            "epoch37, average loss 0.2091 \n",
            "\n",
            "weights: 0.3833 0.8092 0.2399 -0.0707\n",
            "[[0, 0, 0], 0]:0.3655, error=-0.3655, loss=0.0668, grad=0.3167 0.0000 0.0000 0.0000\n",
            "weights: 0.3801 0.8092 0.2399 -0.0707\n",
            "[[0, 0, 1], 1]:0.2999, error=0.7001, loss=0.2451, grad=-0.6371 -0.0000 -0.0000 -0.6371\n",
            "weights: 0.3865 0.8092 0.2399 -0.0643\n",
            "[[0, 1, 0], 1]:0.5555, error=0.4445, loss=0.0988, grad=-0.3073 -0.0000 -0.3073 -0.0000\n",
            "weights: 0.3895 0.8092 0.2430 -0.0643\n",
            "[[1, 0, 0], 1]:0.8333, error=0.1667, loss=0.0139, grad=-0.0510 -0.0510 -0.0000 -0.0000\n",
            "weights: 0.3900 0.8097 0.2430 -0.0643\n",
            "[[0, 1, 1], 0]:0.5144, error=-0.5144, loss=0.1323, grad=0.3783 0.0000 0.3783 0.3783\n",
            "weights: 0.3863 0.8097 0.2392 -0.0681\n",
            "[[1, 0, 1], 0]:0.8103, error=-0.8103, loss=0.3283, grad=0.2783 0.2783 0.0000 0.2783\n",
            "weights: 0.3835 0.8069 0.2392 -0.0709\n",
            "[[1, 1, 0], 0]:0.8916, error=-0.8916, loss=0.3975, grad=0.1828 0.1828 0.1828 0.0000\n",
            "weights: 0.3817 0.8051 0.2374 -0.0709\n",
            "[[1, 1, 1], 0]:0.8748, error=-0.8748, loss=0.3827, grad=0.2053 0.2053 0.2053 0.2053\n",
            "epoch38, average loss 0.2082 \n",
            "\n",
            "weights: 0.3796 0.8031 0.2353 -0.0729\n",
            "[[0, 0, 0], 0]:0.3624, error=-0.3624, loss=0.0657, grad=0.3148 0.0000 0.0000 0.0000\n",
            "weights: 0.3765 0.8031 0.2353 -0.0729\n",
            "[[0, 0, 1], 1]:0.2945, error=0.7055, loss=0.2488, grad=-0.6443 -0.0000 -0.0000 -0.6443\n",
            "weights: 0.3829 0.8031 0.2353 -0.0665\n",
            "[[0, 1, 0], 1]:0.5499, error=0.4501, loss=0.1013, grad=-0.3140 -0.0000 -0.3140 -0.0000\n",
            "weights: 0.3860 0.8031 0.2384 -0.0665\n",
            "[[1, 0, 0], 1]:0.8303, error=0.1697, loss=0.0144, grad=-0.0527 -0.0527 -0.0000 -0.0000\n",
            "weights: 0.3866 0.8036 0.2384 -0.0665\n",
            "[[0, 1, 1], 0]:0.5069, error=-0.5069, loss=0.1285, grad=0.3766 0.0000 0.3766 0.3766\n",
            "weights: 0.3828 0.8036 0.2347 -0.0703\n",
            "[[1, 0, 1], 0]:0.8062, error=-0.8062, loss=0.3250, grad=0.2822 0.2822 0.0000 0.2822\n",
            "weights: 0.3800 0.8008 0.2347 -0.0731\n",
            "[[1, 1, 0], 0]:0.8886, error=-0.8886, loss=0.3948, grad=0.1869 0.1869 0.1869 0.0000\n",
            "weights: 0.3781 0.7989 0.2328 -0.0731\n",
            "[[1, 1, 1], 0]:0.8709, error=-0.8709, loss=0.3792, grad=0.2104 0.2104 0.2104 0.2104\n",
            "epoch39, average loss 0.2072 \n",
            "\n",
            "weights: 0.3760 0.7968 0.2307 -0.0752\n",
            "[[0, 0, 0], 0]:0.3592, error=-0.3592, loss=0.0645, grad=0.3129 0.0000 0.0000 0.0000\n",
            "weights: 0.3729 0.7968 0.2307 -0.0752\n",
            "[[0, 0, 1], 1]:0.2892, error=0.7108, loss=0.2526, grad=-0.6513 -0.0000 -0.0000 -0.6513\n",
            "weights: 0.3794 0.7968 0.2307 -0.0687\n",
            "[[0, 1, 0], 1]:0.5442, error=0.4558, loss=0.1039, grad=-0.3208 -0.0000 -0.3208 -0.0000\n",
            "weights: 0.3826 0.7968 0.2339 -0.0687\n",
            "[[1, 0, 0], 1]:0.8273, error=0.1727, loss=0.0149, grad=-0.0545 -0.0545 -0.0000 -0.0000\n",
            "weights: 0.3831 0.7973 0.2339 -0.0687\n",
            "[[0, 1, 1], 0]:0.4993, error=-0.4993, loss=0.1247, grad=0.3748 0.0000 0.3748 0.3748\n",
            "weights: 0.3794 0.7973 0.2302 -0.0724\n",
            "[[1, 0, 1], 0]:0.8020, error=-0.8020, loss=0.3216, grad=0.2861 0.2861 0.0000 0.2861\n",
            "weights: 0.3765 0.7945 0.2302 -0.0753\n",
            "[[1, 1, 0], 0]:0.8856, error=-0.8856, loss=0.3921, grad=0.1910 0.1910 0.1910 0.0000\n",
            "weights: 0.3746 0.7926 0.2282 -0.0753\n",
            "[[1, 1, 1], 0]:0.8668, error=-0.8668, loss=0.3757, grad=0.2155 0.2155 0.2155 0.2155\n",
            "epoch40, average loss 0.2063 \n",
            "\n",
            "weights: 0.3725 0.7904 0.2261 -0.0774\n",
            "[[0, 0, 0], 0]:0.3561, error=-0.3561, loss=0.0634, grad=0.3110 0.0000 0.0000 0.0000\n",
            "weights: 0.3694 0.7904 0.2261 -0.0774\n",
            "[[0, 0, 1], 1]:0.2839, error=0.7161, loss=0.2564, grad=-0.6584 -0.0000 -0.0000 -0.6584\n",
            "weights: 0.3759 0.7904 0.2261 -0.0708\n",
            "[[0, 1, 0], 1]:0.5385, error=0.4615, loss=0.1065, grad=-0.3277 -0.0000 -0.3277 -0.0000\n",
            "weights: 0.3792 0.7904 0.2294 -0.0708\n",
            "[[1, 0, 0], 1]:0.8242, error=0.1758, loss=0.0155, grad=-0.0564 -0.0564 -0.0000 -0.0000\n",
            "weights: 0.3798 0.7910 0.2294 -0.0708\n",
            "[[0, 1, 1], 0]:0.4917, error=-0.4917, loss=0.1209, grad=0.3728 0.0000 0.3728 0.3728\n",
            "weights: 0.3760 0.7910 0.2256 -0.0746\n",
            "[[1, 0, 1], 0]:0.7978, error=-0.7978, loss=0.3182, grad=0.2900 0.2900 0.0000 0.2900\n",
            "weights: 0.3731 0.7881 0.2256 -0.0775\n",
            "[[1, 1, 0], 0]:0.8825, error=-0.8825, loss=0.3894, grad=0.1952 0.1952 0.1952 0.0000\n",
            "weights: 0.3712 0.7861 0.2237 -0.0775\n",
            "[[1, 1, 1], 0]:0.8626, error=-0.8626, loss=0.3721, grad=0.2207 0.2207 0.2207 0.2207\n",
            "epoch41, average loss 0.2053 \n",
            "\n",
            "weights: 0.3690 0.7839 0.2215 -0.0797\n",
            "[[0, 0, 0], 0]:0.3531, error=-0.3531, loss=0.0623, grad=0.3091 0.0000 0.0000 0.0000\n",
            "weights: 0.3659 0.7839 0.2215 -0.0797\n",
            "[[0, 0, 1], 1]:0.2787, error=0.7213, loss=0.2602, grad=-0.6653 -0.0000 -0.0000 -0.6653\n",
            "weights: 0.3726 0.7839 0.2215 -0.0730\n",
            "[[0, 1, 0], 1]:0.5328, error=0.4672, loss=0.1091, grad=-0.3346 -0.0000 -0.3346 -0.0000\n",
            "weights: 0.3759 0.7839 0.2248 -0.0730\n",
            "[[1, 0, 0], 1]:0.8210, error=0.1790, loss=0.0160, grad=-0.0584 -0.0584 -0.0000 -0.0000\n",
            "weights: 0.3765 0.7845 0.2248 -0.0730\n",
            "[[0, 1, 1], 0]:0.4841, error=-0.4841, loss=0.1172, grad=0.3706 0.0000 0.3706 0.3706\n",
            "weights: 0.3728 0.7845 0.2211 -0.0767\n",
            "[[1, 0, 1], 0]:0.7934, error=-0.7934, loss=0.3147, grad=0.2940 0.2940 0.0000 0.2940\n",
            "weights: 0.3698 0.7816 0.2211 -0.0797\n",
            "[[1, 1, 0], 0]:0.8793, error=-0.8793, loss=0.3866, grad=0.1995 0.1995 0.1995 0.0000\n",
            "weights: 0.3678 0.7796 0.2191 -0.0797\n",
            "[[1, 1, 1], 0]:0.8583, error=-0.8583, loss=0.3683, grad=0.2260 0.2260 0.2260 0.2260\n",
            "epoch42, average loss 0.2043 \n",
            "\n",
            "weights: 0.3656 0.7773 0.2169 -0.0819\n",
            "[[0, 0, 0], 0]:0.3501, error=-0.3501, loss=0.0613, grad=0.3072 0.0000 0.0000 0.0000\n",
            "weights: 0.3625 0.7773 0.2169 -0.0819\n",
            "[[0, 0, 1], 1]:0.2734, error=0.7266, loss=0.2639, grad=-0.6722 -0.0000 -0.0000 -0.6722\n",
            "weights: 0.3692 0.7773 0.2169 -0.0752\n",
            "[[0, 1, 0], 1]:0.5271, error=0.4729, loss=0.1118, grad=-0.3415 -0.0000 -0.3415 -0.0000\n",
            "weights: 0.3726 0.7773 0.2203 -0.0752\n",
            "[[1, 0, 0], 1]:0.8177, error=0.1823, loss=0.0166, grad=-0.0604 -0.0604 -0.0000 -0.0000\n",
            "weights: 0.3733 0.7779 0.2203 -0.0752\n",
            "[[0, 1, 1], 0]:0.4764, error=-0.4764, loss=0.1135, grad=0.3683 0.0000 0.3683 0.3683\n",
            "weights: 0.3696 0.7779 0.2166 -0.0789\n",
            "[[1, 0, 1], 0]:0.7889, error=-0.7889, loss=0.3112, grad=0.2979 0.2979 0.0000 0.2979\n",
            "weights: 0.3666 0.7749 0.2166 -0.0819\n",
            "[[1, 1, 0], 0]:0.8760, error=-0.8760, loss=0.3836, grad=0.2038 0.2038 0.2038 0.0000\n",
            "weights: 0.3646 0.7729 0.2146 -0.0819\n",
            "[[1, 1, 1], 0]:0.8538, error=-0.8538, loss=0.3645, grad=0.2314 0.2314 0.2314 0.2314\n",
            "epoch43, average loss 0.2033 \n",
            "\n",
            "weights: 0.3622 0.7706 0.2122 -0.0842\n",
            "[[0, 0, 0], 0]:0.3472, error=-0.3472, loss=0.0603, grad=0.3053 0.0000 0.0000 0.0000\n",
            "weights: 0.3592 0.7706 0.2122 -0.0842\n",
            "[[0, 0, 1], 1]:0.2683, error=0.7317, loss=0.2677, grad=-0.6791 -0.0000 -0.0000 -0.6791\n",
            "weights: 0.3660 0.7706 0.2122 -0.0774\n",
            "[[0, 1, 0], 1]:0.5214, error=0.4786, loss=0.1145, grad=-0.3485 -0.0000 -0.3485 -0.0000\n",
            "weights: 0.3695 0.7706 0.2157 -0.0774\n",
            "[[1, 0, 0], 1]:0.8144, error=0.1856, loss=0.0172, grad=-0.0625 -0.0625 -0.0000 -0.0000\n",
            "weights: 0.3701 0.7712 0.2157 -0.0774\n",
            "[[0, 1, 1], 0]:0.4687, error=-0.4687, loss=0.1098, grad=0.3657 0.0000 0.3657 0.3657\n",
            "weights: 0.3664 0.7712 0.2121 -0.0811\n",
            "[[1, 0, 1], 0]:0.7844, error=-0.7844, loss=0.3076, grad=0.3018 0.3018 0.0000 0.3018\n",
            "weights: 0.3634 0.7682 0.2121 -0.0841\n",
            "[[1, 1, 0], 0]:0.8726, error=-0.8726, loss=0.3807, grad=0.2082 0.2082 0.2082 0.0000\n",
            "weights: 0.3613 0.7661 0.2100 -0.0841\n",
            "[[1, 1, 1], 0]:0.8492, error=-0.8492, loss=0.3606, grad=0.2368 0.2368 0.2368 0.2368\n",
            "epoch44, average loss 0.2023 \n",
            "\n",
            "weights: 0.3590 0.7637 0.2076 -0.0864\n",
            "[[0, 0, 0], 0]:0.3443, error=-0.3443, loss=0.0593, grad=0.3035 0.0000 0.0000 0.0000\n",
            "weights: 0.3559 0.7637 0.2076 -0.0864\n",
            "[[0, 0, 1], 1]:0.2631, error=0.7369, loss=0.2715, grad=-0.6858 -0.0000 -0.0000 -0.6858\n",
            "weights: 0.3628 0.7637 0.2076 -0.0796\n",
            "[[0, 1, 0], 1]:0.5157, error=0.4843, loss=0.1173, grad=-0.3556 -0.0000 -0.3556 -0.0000\n",
            "weights: 0.3663 0.7637 0.2112 -0.0796\n",
            "[[1, 0, 0], 1]:0.8110, error=0.1890, loss=0.0179, grad=-0.0647 -0.0647 -0.0000 -0.0000\n",
            "weights: 0.3670 0.7644 0.2112 -0.0796\n",
            "[[0, 1, 1], 0]:0.4610, error=-0.4610, loss=0.1063, grad=0.3630 0.0000 0.3630 0.3630\n",
            "weights: 0.3634 0.7644 0.2076 -0.0832\n",
            "[[1, 0, 1], 0]:0.7797, error=-0.7797, loss=0.3039, grad=0.3057 0.3057 0.0000 0.3057\n",
            "weights: 0.3603 0.7613 0.2076 -0.0863\n",
            "[[1, 1, 0], 0]:0.8690, error=-0.8690, loss=0.3776, grad=0.2127 0.2127 0.2127 0.0000\n",
            "weights: 0.3582 0.7592 0.2054 -0.0863\n",
            "[[1, 1, 1], 0]:0.8445, error=-0.8445, loss=0.3566, grad=0.2423 0.2423 0.2423 0.2423\n",
            "epoch45, average loss 0.2013 \n",
            "\n",
            "weights: 0.3557 0.7568 0.2030 -0.0887\n",
            "[[0, 0, 0], 0]:0.3415, error=-0.3415, loss=0.0583, grad=0.3016 0.0000 0.0000 0.0000\n",
            "weights: 0.3527 0.7568 0.2030 -0.0887\n",
            "[[0, 0, 1], 1]:0.2581, error=0.7419, loss=0.2752, grad=-0.6925 -0.0000 -0.0000 -0.6925\n",
            "weights: 0.3597 0.7568 0.2030 -0.0818\n",
            "[[0, 1, 0], 1]:0.5099, error=0.4901, loss=0.1201, grad=-0.3626 -0.0000 -0.3626 -0.0000\n",
            "weights: 0.3633 0.7568 0.2066 -0.0818\n",
            "[[1, 0, 0], 1]:0.8076, error=0.1924, loss=0.0185, grad=-0.0669 -0.0669 -0.0000 -0.0000\n",
            "weights: 0.3640 0.7574 0.2066 -0.0818\n",
            "[[0, 1, 1], 0]:0.4533, error=-0.4533, loss=0.1027, grad=0.3601 0.0000 0.3601 0.3601\n",
            "weights: 0.3603 0.7574 0.2030 -0.0854\n",
            "[[1, 0, 1], 0]:0.7749, error=-0.7749, loss=0.3002, grad=0.3096 0.3096 0.0000 0.3096\n",
            "weights: 0.3573 0.7543 0.2030 -0.0885\n",
            "[[1, 1, 0], 0]:0.8654, error=-0.8654, loss=0.3745, grad=0.2172 0.2172 0.2172 0.0000\n",
            "weights: 0.3551 0.7522 0.2009 -0.0885\n",
            "[[1, 1, 1], 0]:0.8396, error=-0.8396, loss=0.3524, grad=0.2478 0.2478 0.2478 0.2478\n",
            "epoch46, average loss 0.2002 \n",
            "\n",
            "weights: 0.3526 0.7497 0.1984 -0.0909\n",
            "[[0, 0, 0], 0]:0.3387, error=-0.3387, loss=0.0574, grad=0.2998 0.0000 0.0000 0.0000\n",
            "weights: 0.3496 0.7497 0.1984 -0.0909\n",
            "[[0, 0, 1], 1]:0.2530, error=0.7470, loss=0.2790, grad=-0.6991 -0.0000 -0.0000 -0.6991\n",
            "weights: 0.3566 0.7497 0.1984 -0.0839\n",
            "[[0, 1, 0], 1]:0.5042, error=0.4958, loss=0.1229, grad=-0.3697 -0.0000 -0.3697 -0.0000\n",
            "weights: 0.3603 0.7497 0.2021 -0.0839\n",
            "[[1, 0, 0], 1]:0.8041, error=0.1959, loss=0.0192, grad=-0.0693 -0.0693 -0.0000 -0.0000\n",
            "weights: 0.3610 0.7504 0.2021 -0.0839\n",
            "[[0, 1, 1], 0]:0.4455, error=-0.4455, loss=0.0992, grad=0.3571 0.0000 0.3571 0.3571\n",
            "weights: 0.3574 0.7504 0.1985 -0.0875\n",
            "[[1, 0, 1], 0]:0.7700, error=-0.7700, loss=0.2964, grad=0.3135 0.3135 0.0000 0.3135\n",
            "weights: 0.3543 0.7473 0.1985 -0.0907\n",
            "[[1, 1, 0], 0]:0.8617, error=-0.8617, loss=0.3713, grad=0.2218 0.2218 0.2218 0.0000\n",
            "weights: 0.3521 0.7450 0.1963 -0.0907\n",
            "[[1, 1, 1], 0]:0.8345, error=-0.8345, loss=0.3482, grad=0.2534 0.2534 0.2534 0.2534\n",
            "epoch47, average loss 0.1992 \n",
            "\n",
            "weights: 0.3495 0.7425 0.1937 -0.0932\n",
            "[[0, 0, 0], 0]:0.3360, error=-0.3360, loss=0.0564, grad=0.2980 0.0000 0.0000 0.0000\n",
            "weights: 0.3465 0.7425 0.1937 -0.0932\n",
            "[[0, 0, 1], 1]:0.2481, error=0.7519, loss=0.2827, grad=-0.7057 -0.0000 -0.0000 -0.7057\n",
            "weights: 0.3536 0.7425 0.1937 -0.0861\n",
            "[[0, 1, 0], 1]:0.4985, error=0.5015, loss=0.1257, grad=-0.3768 -0.0000 -0.3768 -0.0000\n",
            "weights: 0.3574 0.7425 0.1975 -0.0861\n",
            "[[1, 0, 0], 1]:0.8005, error=0.1995, loss=0.0199, grad=-0.0717 -0.0717 -0.0000 -0.0000\n",
            "weights: 0.3581 0.7432 0.1975 -0.0861\n",
            "[[0, 1, 1], 0]:0.4378, error=-0.4378, loss=0.0958, grad=0.3539 0.0000 0.3539 0.3539\n",
            "weights: 0.3546 0.7432 0.1940 -0.0897\n",
            "[[1, 0, 1], 0]:0.7650, error=-0.7650, loss=0.2926, grad=0.3173 0.3173 0.0000 0.3173\n",
            "weights: 0.3514 0.7400 0.1940 -0.0928\n",
            "[[1, 1, 0], 0]:0.8579, error=-0.8579, loss=0.3680, grad=0.2265 0.2265 0.2265 0.0000\n",
            "weights: 0.3491 0.7378 0.1917 -0.0928\n",
            "[[1, 1, 1], 0]:0.8293, error=-0.8293, loss=0.3438, grad=0.2590 0.2590 0.2590 0.2590\n",
            "epoch48, average loss 0.1981 \n",
            "\n",
            "weights: 0.3465 0.7352 0.1891 -0.0954\n",
            "[[0, 0, 0], 0]:0.3333, error=-0.3333, loss=0.0555, grad=0.2963 0.0000 0.0000 0.0000\n",
            "weights: 0.3436 0.7352 0.1891 -0.0954\n",
            "[[0, 0, 1], 1]:0.2432, error=0.7568, loss=0.2864, grad=-0.7121 -0.0000 -0.0000 -0.7121\n",
            "weights: 0.3507 0.7352 0.1891 -0.0883\n",
            "[[0, 1, 0], 1]:0.4928, error=0.5072, loss=0.1286, grad=-0.3840 -0.0000 -0.3840 -0.0000\n",
            "weights: 0.3545 0.7352 0.1930 -0.0883\n",
            "[[1, 0, 0], 1]:0.7968, error=0.2032, loss=0.0207, grad=-0.0742 -0.0742 -0.0000 -0.0000\n",
            "weights: 0.3553 0.7359 0.1930 -0.0883\n",
            "[[0, 1, 1], 0]:0.4300, error=-0.4300, loss=0.0925, grad=0.3505 0.0000 0.3505 0.3505\n",
            "weights: 0.3518 0.7359 0.1895 -0.0918\n",
            "[[1, 0, 1], 0]:0.7599, error=-0.7599, loss=0.2887, grad=0.3211 0.3211 0.0000 0.3211\n",
            "weights: 0.3485 0.7327 0.1895 -0.0950\n",
            "[[1, 1, 0], 0]:0.8540, error=-0.8540, loss=0.3647, grad=0.2312 0.2312 0.2312 0.0000\n",
            "weights: 0.3462 0.7304 0.1871 -0.0950\n",
            "[[1, 1, 1], 0]:0.8239, error=-0.8239, loss=0.3394, grad=0.2647 0.2647 0.2647 0.2647\n",
            "epoch49, average loss 0.1970 \n",
            "\n",
            "weights: 0.3436 0.7278 0.1845 -0.0977\n",
            "[[0, 0, 0], 0]:0.3307, error=-0.3307, loss=0.0547, grad=0.2945 0.0000 0.0000 0.0000\n",
            "weights: 0.3406 0.7278 0.1845 -0.0977\n",
            "[[0, 0, 1], 1]:0.2383, error=0.7617, loss=0.2901, grad=-0.7184 -0.0000 -0.0000 -0.7184\n",
            "weights: 0.3478 0.7278 0.1845 -0.0905\n",
            "[[0, 1, 0], 1]:0.4872, error=0.5128, loss=0.1315, grad=-0.3911 -0.0000 -0.3911 -0.0000\n",
            "weights: 0.3517 0.7278 0.1884 -0.0905\n",
            "[[1, 0, 0], 1]:0.7930, error=0.2070, loss=0.0214, grad=-0.0768 -0.0768 -0.0000 -0.0000\n",
            "weights: 0.3525 0.7285 0.1884 -0.0905\n",
            "[[0, 1, 1], 0]:0.4223, error=-0.4223, loss=0.0891, grad=0.3470 0.0000 0.3470 0.3470\n",
            "weights: 0.3490 0.7285 0.1849 -0.0940\n",
            "[[1, 0, 1], 0]:0.7546, error=-0.7546, loss=0.2847, grad=0.3249 0.3249 0.0000 0.3249\n",
            "weights: 0.3458 0.7253 0.1849 -0.0972\n",
            "[[1, 1, 0], 0]:0.8500, error=-0.8500, loss=0.3612, grad=0.2359 0.2359 0.2359 0.0000\n",
            "weights: 0.3434 0.7229 0.1826 -0.0972\n",
            "[[1, 1, 1], 0]:0.8183, error=-0.8183, loss=0.3348, grad=0.2703 0.2703 0.2703 0.2703\n",
            "epoch50, average loss 0.1960 \n",
            "\n",
            "weights: 0.3407 0.7202 0.1799 -0.0999\n",
            "[[0, 0, 0], 0]:0.3281, error=-0.3281, loss=0.0538, grad=0.2928 0.0000 0.0000 0.0000\n",
            "weights: 0.3378 0.7202 0.1799 -0.0999\n",
            "[[0, 0, 1], 1]:0.2335, error=0.7665, loss=0.2938, grad=-0.7247 -0.0000 -0.0000 -0.7247\n",
            "weights: 0.3450 0.7202 0.1799 -0.0927\n",
            "[[0, 1, 0], 1]:0.4815, error=0.5185, loss=0.1344, grad=-0.3983 -0.0000 -0.3983 -0.0000\n",
            "weights: 0.3490 0.7202 0.1839 -0.0927\n",
            "[[1, 0, 0], 1]:0.7892, error=0.2108, loss=0.0222, grad=-0.0795 -0.0795 -0.0000 -0.0000\n",
            "weights: 0.3498 0.7210 0.1839 -0.0927\n",
            "[[0, 1, 1], 0]:0.4145, error=-0.4145, loss=0.0859, grad=0.3433 0.0000 0.3433 0.3433\n",
            "weights: 0.3464 0.7210 0.1804 -0.0961\n",
            "[[1, 0, 1], 0]:0.7493, error=-0.7493, loss=0.2807, grad=0.3286 0.3286 0.0000 0.3286\n",
            "weights: 0.3431 0.7177 0.1804 -0.0994\n",
            "[[1, 1, 0], 0]:0.8458, error=-0.8458, loss=0.3577, grad=0.2407 0.2407 0.2407 0.0000\n",
            "weights: 0.3407 0.7153 0.1780 -0.0994\n",
            "[[1, 1, 1], 0]:0.8126, error=-0.8126, loss=0.3302, grad=0.2760 0.2760 0.2760 0.2760\n",
            "epoch51, average loss 0.1948 \n",
            "\n",
            "weights: 0.3379 0.7126 0.1753 -0.1021\n",
            "[[0, 0, 0], 0]:0.3256, error=-0.3256, loss=0.0530, grad=0.2911 0.0000 0.0000 0.0000\n",
            "weights: 0.3350 0.7126 0.1753 -0.1021\n",
            "[[0, 0, 1], 1]:0.2288, error=0.7712, loss=0.2974, grad=-0.7309 -0.0000 -0.0000 -0.7309\n",
            "weights: 0.3423 0.7126 0.1753 -0.0948\n",
            "[[0, 1, 0], 1]:0.4758, error=0.5242, loss=0.1374, grad=-0.4055 -0.0000 -0.4055 -0.0000\n",
            "weights: 0.3464 0.7126 0.1793 -0.0948\n",
            "[[1, 0, 0], 1]:0.7853, error=0.2147, loss=0.0231, grad=-0.0823 -0.0823 -0.0000 -0.0000\n",
            "weights: 0.3472 0.7134 0.1793 -0.0948\n",
            "[[0, 1, 1], 0]:0.4067, error=-0.4067, loss=0.0827, grad=0.3394 0.0000 0.3394 0.3394\n",
            "weights: 0.3438 0.7134 0.1759 -0.0982\n",
            "[[1, 0, 1], 0]:0.7438, error=-0.7438, loss=0.2766, grad=0.3323 0.3323 0.0000 0.3323\n",
            "weights: 0.3405 0.7101 0.1759 -0.1016\n",
            "[[1, 1, 0], 0]:0.8416, error=-0.8416, loss=0.3541, grad=0.2456 0.2456 0.2456 0.0000\n",
            "weights: 0.3380 0.7076 0.1735 -0.1016\n",
            "[[1, 1, 1], 0]:0.8067, error=-0.8067, loss=0.3254, grad=0.2817 0.2817 0.2817 0.2817\n",
            "epoch52, average loss 0.1937 \n",
            "\n",
            "weights: 0.3352 0.7048 0.1707 -0.1044\n",
            "[[0, 0, 0], 0]:0.3232, error=-0.3232, loss=0.0522, grad=0.2894 0.0000 0.0000 0.0000\n",
            "weights: 0.3323 0.7048 0.1707 -0.1044\n",
            "[[0, 0, 1], 1]:0.2241, error=0.7759, loss=0.3010, grad=-0.7369 -0.0000 -0.0000 -0.7369\n",
            "weights: 0.3397 0.7048 0.1707 -0.0970\n",
            "[[0, 1, 0], 1]:0.4702, error=0.5298, loss=0.1403, grad=-0.4126 -0.0000 -0.4126 -0.0000\n",
            "weights: 0.3438 0.7048 0.1748 -0.0970\n",
            "[[1, 0, 0], 1]:0.7813, error=0.2187, loss=0.0239, grad=-0.0852 -0.0852 -0.0000 -0.0000\n",
            "weights: 0.3447 0.7056 0.1748 -0.0970\n",
            "[[0, 1, 1], 0]:0.3990, error=-0.3990, loss=0.0796, grad=0.3355 0.0000 0.3355 0.3355\n",
            "weights: 0.3413 0.7056 0.1714 -0.1004\n",
            "[[1, 0, 1], 0]:0.7382, error=-0.7382, loss=0.2725, grad=0.3359 0.3359 0.0000 0.3359\n",
            "weights: 0.3380 0.7023 0.1714 -0.1037\n",
            "[[1, 1, 0], 0]:0.8372, error=-0.8372, loss=0.3504, grad=0.2504 0.2504 0.2504 0.0000\n",
            "weights: 0.3355 0.6998 0.1689 -0.1037\n",
            "[[1, 1, 1], 0]:0.8007, error=-0.8007, loss=0.3205, grad=0.2874 0.2874 0.2874 0.2874\n",
            "epoch53, average loss 0.1926 \n",
            "\n",
            "weights: 0.3326 0.6969 0.1660 -0.1066\n",
            "[[0, 0, 0], 0]:0.3208, error=-0.3208, loss=0.0515, grad=0.2878 0.0000 0.0000 0.0000\n",
            "weights: 0.3297 0.6969 0.1660 -0.1066\n",
            "[[0, 0, 1], 1]:0.2195, error=0.7805, loss=0.3046, grad=-0.7429 -0.0000 -0.0000 -0.7429\n",
            "weights: 0.3371 0.6969 0.1660 -0.0992\n",
            "[[0, 1, 0], 1]:0.4646, error=0.5354, loss=0.1433, grad=-0.4198 -0.0000 -0.4198 -0.0000\n",
            "weights: 0.3413 0.6969 0.1702 -0.0992\n",
            "[[1, 0, 0], 1]:0.7772, error=0.2228, loss=0.0248, grad=-0.0882 -0.0882 -0.0000 -0.0000\n",
            "weights: 0.3422 0.6978 0.1702 -0.0992\n",
            "[[0, 1, 1], 0]:0.3913, error=-0.3913, loss=0.0765, grad=0.3314 0.0000 0.3314 0.3314\n",
            "weights: 0.3389 0.6978 0.1669 -0.1025\n",
            "[[1, 0, 1], 0]:0.7326, error=-0.7326, loss=0.2683, grad=0.3394 0.3394 0.0000 0.3394\n",
            "weights: 0.3355 0.6944 0.1669 -0.1059\n",
            "[[1, 1, 0], 0]:0.8327, error=-0.8327, loss=0.3467, grad=0.2553 0.2553 0.2553 0.0000\n",
            "weights: 0.3330 0.6918 0.1644 -0.1059\n",
            "[[1, 1, 1], 0]:0.7944, error=-0.7944, loss=0.3156, grad=0.2931 0.2931 0.2931 0.2931\n",
            "epoch54, average loss 0.1914 \n",
            "\n",
            "weights: 0.3300 0.6889 0.1614 -0.1088\n",
            "[[0, 0, 0], 0]:0.3185, error=-0.3185, loss=0.0507, grad=0.2862 0.0000 0.0000 0.0000\n",
            "weights: 0.3272 0.6889 0.1614 -0.1088\n",
            "[[0, 0, 1], 1]:0.2150, error=0.7850, loss=0.3081, grad=-0.7488 -0.0000 -0.0000 -0.7488\n",
            "weights: 0.3346 0.6889 0.1614 -0.1013\n",
            "[[0, 1, 0], 1]:0.4590, error=0.5410, loss=0.1463, grad=-0.4270 -0.0000 -0.4270 -0.0000\n",
            "weights: 0.3389 0.6889 0.1657 -0.1013\n",
            "[[1, 0, 0], 1]:0.7730, error=0.2270, loss=0.0258, grad=-0.0913 -0.0913 -0.0000 -0.0000\n",
            "weights: 0.3398 0.6898 0.1657 -0.1013\n",
            "[[0, 1, 1], 0]:0.3836, error=-0.3836, loss=0.0736, grad=0.3271 0.0000 0.3271 0.3271\n",
            "weights: 0.3366 0.6898 0.1624 -0.1046\n",
            "[[1, 0, 1], 0]:0.7267, error=-0.7267, loss=0.2641, grad=0.3429 0.3429 0.0000 0.3429\n",
            "weights: 0.3331 0.6864 0.1624 -0.1080\n",
            "[[1, 1, 0], 0]:0.8281, error=-0.8281, loss=0.3429, grad=0.2603 0.2603 0.2603 0.0000\n",
            "weights: 0.3305 0.6838 0.1598 -0.1080\n",
            "[[1, 1, 1], 0]:0.7880, error=-0.7880, loss=0.3105, grad=0.2987 0.2987 0.2987 0.2987\n",
            "epoch55, average loss 0.1902 \n",
            "\n",
            "weights: 0.3275 0.6808 0.1569 -0.1110\n",
            "[[0, 0, 0], 0]:0.3163, error=-0.3163, loss=0.0500, grad=0.2847 0.0000 0.0000 0.0000\n",
            "weights: 0.3247 0.6808 0.1569 -0.1110\n",
            "[[0, 0, 1], 1]:0.2105, error=0.7895, loss=0.3117, grad=-0.7545 -0.0000 -0.0000 -0.7545\n",
            "weights: 0.3322 0.6808 0.1569 -0.1035\n",
            "[[0, 1, 0], 1]:0.4535, error=0.5465, loss=0.1493, grad=-0.4341 -0.0000 -0.4341 -0.0000\n",
            "weights: 0.3366 0.6808 0.1612 -0.1035\n",
            "[[1, 0, 0], 1]:0.7688, error=0.2312, loss=0.0267, grad=-0.0945 -0.0945 -0.0000 -0.0000\n",
            "weights: 0.3375 0.6818 0.1612 -0.1035\n",
            "[[0, 1, 1], 0]:0.3759, error=-0.3759, loss=0.0706, grad=0.3228 0.0000 0.3228 0.3228\n",
            "weights: 0.3343 0.6818 0.1580 -0.1067\n",
            "[[1, 0, 1], 0]:0.7208, error=-0.7208, loss=0.2598, grad=0.3463 0.3463 0.0000 0.3463\n",
            "weights: 0.3308 0.6783 0.1580 -0.1101\n",
            "[[1, 1, 0], 0]:0.8233, error=-0.8233, loss=0.3389, grad=0.2652 0.2652 0.2652 0.0000\n",
            "weights: 0.3282 0.6756 0.1553 -0.1101\n",
            "[[1, 1, 1], 0]:0.7814, error=-0.7814, loss=0.3053, grad=0.3043 0.3043 0.3043 0.3043\n",
            "epoch56, average loss 0.1891 \n",
            "\n",
            "weights: 0.3251 0.6726 0.1523 -0.1132\n",
            "[[0, 0, 0], 0]:0.3141, error=-0.3141, loss=0.0493, grad=0.2831 0.0000 0.0000 0.0000\n",
            "weights: 0.3223 0.6726 0.1523 -0.1132\n",
            "[[0, 0, 1], 1]:0.2061, error=0.7939, loss=0.3151, grad=-0.7601 -0.0000 -0.0000 -0.7601\n",
            "weights: 0.3299 0.6726 0.1523 -0.1056\n",
            "[[0, 1, 0], 1]:0.4480, error=0.5520, loss=0.1524, grad=-0.4412 -0.0000 -0.4412 -0.0000\n",
            "weights: 0.3343 0.6726 0.1567 -0.1056\n",
            "[[1, 0, 0], 1]:0.7645, error=0.2355, loss=0.0277, grad=-0.0979 -0.0979 -0.0000 -0.0000\n",
            "weights: 0.3353 0.6736 0.1567 -0.1056\n",
            "[[0, 1, 1], 0]:0.3683, error=-0.3683, loss=0.0678, grad=0.3183 0.0000 0.3183 0.3183\n",
            "weights: 0.3321 0.6736 0.1535 -0.1088\n",
            "[[1, 0, 1], 0]:0.7148, error=-0.7148, loss=0.2555, grad=0.3496 0.3496 0.0000 0.3496\n",
            "weights: 0.3286 0.6701 0.1535 -0.1123\n",
            "[[1, 1, 0], 0]:0.8185, error=-0.8185, loss=0.3350, grad=0.2702 0.2702 0.2702 0.0000\n",
            "weights: 0.3259 0.6674 0.1508 -0.1123\n",
            "[[1, 1, 1], 0]:0.7746, error=-0.7746, loss=0.3000, grad=0.3098 0.3098 0.3098 0.3098\n",
            "epoch57, average loss 0.1879 \n",
            "\n",
            "weights: 0.3228 0.6643 0.1477 -0.1154\n",
            "[[0, 0, 0], 0]:0.3121, error=-0.3121, loss=0.0487, grad=0.2817 0.0000 0.0000 0.0000\n",
            "weights: 0.3200 0.6643 0.1477 -0.1154\n",
            "[[0, 0, 1], 1]:0.2018, error=0.7982, loss=0.3185, grad=-0.7656 -0.0000 -0.0000 -0.7656\n",
            "weights: 0.3277 0.6643 0.1477 -0.1077\n",
            "[[0, 1, 0], 1]:0.4425, error=0.5575, loss=0.1554, grad=-0.4483 -0.0000 -0.4483 -0.0000\n",
            "weights: 0.3321 0.6643 0.1522 -0.1077\n",
            "[[1, 0, 0], 1]:0.7601, error=0.2399, loss=0.0288, grad=-0.1013 -0.1013 -0.0000 -0.0000\n",
            "weights: 0.3332 0.6653 0.1522 -0.1077\n",
            "[[0, 1, 1], 0]:0.3607, error=-0.3607, loss=0.0650, grad=0.3137 0.0000 0.3137 0.3137\n",
            "weights: 0.3300 0.6653 0.1490 -0.1108\n",
            "[[1, 0, 1], 0]:0.7087, error=-0.7087, loss=0.2511, grad=0.3528 0.3528 0.0000 0.3528\n",
            "weights: 0.3265 0.6618 0.1490 -0.1144\n",
            "[[1, 1, 0], 0]:0.8135, error=-0.8135, loss=0.3309, grad=0.2751 0.2751 0.2751 0.0000\n",
            "weights: 0.3237 0.6590 0.1463 -0.1144\n",
            "[[1, 1, 1], 0]:0.7677, error=-0.7677, loss=0.2947, grad=0.3153 0.3153 0.3153 0.3153\n",
            "epoch58, average loss 0.1866 \n",
            "\n",
            "weights: 0.3206 0.6559 0.1431 -0.1175\n",
            "[[0, 0, 0], 0]:0.3100, error=-0.3100, loss=0.0481, grad=0.2802 0.0000 0.0000 0.0000\n",
            "weights: 0.3178 0.6559 0.1431 -0.1175\n",
            "[[0, 0, 1], 1]:0.1976, error=0.8024, loss=0.3219, grad=-0.7710 -0.0000 -0.0000 -0.7710\n",
            "weights: 0.3255 0.6559 0.1431 -0.1098\n",
            "[[0, 1, 0], 1]:0.4371, error=0.5629, loss=0.1584, grad=-0.4554 -0.0000 -0.4554 -0.0000\n",
            "weights: 0.3301 0.6559 0.1477 -0.1098\n",
            "[[1, 0, 0], 1]:0.7556, error=0.2444, loss=0.0299, grad=-0.1049 -0.1049 -0.0000 -0.0000\n",
            "weights: 0.3311 0.6569 0.1477 -0.1098\n",
            "[[0, 1, 1], 0]:0.3531, error=-0.3531, loss=0.0623, grad=0.3091 0.0000 0.3091 0.3091\n",
            "weights: 0.3280 0.6569 0.1446 -0.1129\n",
            "[[1, 0, 1], 0]:0.7024, error=-0.7024, loss=0.2467, grad=0.3559 0.3559 0.0000 0.3559\n",
            "weights: 0.3245 0.6533 0.1446 -0.1165\n",
            "[[1, 1, 0], 0]:0.8084, error=-0.8084, loss=0.3268, grad=0.2801 0.2801 0.2801 0.0000\n",
            "weights: 0.3217 0.6505 0.1418 -0.1165\n",
            "[[1, 1, 1], 0]:0.7606, error=-0.7606, loss=0.2892, grad=0.3206 0.3206 0.3206 0.3206\n",
            "epoch59, average loss 0.1854 \n",
            "\n",
            "weights: 0.3184 0.6473 0.1386 -0.1197\n",
            "[[0, 0, 0], 0]:0.3081, error=-0.3081, loss=0.0475, grad=0.2789 0.0000 0.0000 0.0000\n",
            "weights: 0.3157 0.6473 0.1386 -0.1197\n",
            "[[0, 0, 1], 1]:0.1935, error=0.8065, loss=0.3252, grad=-0.7763 -0.0000 -0.0000 -0.7763\n",
            "weights: 0.3234 0.6473 0.1386 -0.1119\n",
            "[[0, 1, 0], 1]:0.4317, error=0.5683, loss=0.1615, grad=-0.4624 -0.0000 -0.4624 -0.0000\n",
            "weights: 0.3280 0.6473 0.1432 -0.1119\n",
            "[[1, 0, 0], 1]:0.7511, error=0.2489, loss=0.0310, grad=-0.1085 -0.1085 -0.0000 -0.0000\n",
            "weights: 0.3291 0.6484 0.1432 -0.1119\n",
            "[[0, 1, 1], 0]:0.3456, error=-0.3456, loss=0.0597, grad=0.3043 0.0000 0.3043 0.3043\n",
            "weights: 0.3261 0.6484 0.1402 -0.1149\n",
            "[[1, 0, 1], 0]:0.6960, error=-0.6960, loss=0.2422, grad=0.3588 0.3588 0.0000 0.3588\n",
            "weights: 0.3225 0.6448 0.1402 -0.1185\n",
            "[[1, 1, 0], 0]:0.8032, error=-0.8032, loss=0.3225, grad=0.2850 0.2850 0.2850 0.0000\n",
            "weights: 0.3196 0.6420 0.1373 -0.1185\n",
            "[[1, 1, 1], 0]:0.7532, error=-0.7532, loss=0.2837, grad=0.3259 0.3259 0.3259 0.3259\n",
            "epoch60, average loss 0.1842 \n",
            "\n",
            "weights: 0.3164 0.6387 0.1341 -0.1218\n",
            "[[0, 0, 0], 0]:0.3062, error=-0.3062, loss=0.0469, grad=0.2775 0.0000 0.0000 0.0000\n",
            "weights: 0.3136 0.6387 0.1341 -0.1218\n",
            "[[0, 0, 1], 1]:0.1895, error=0.8105, loss=0.3285, grad=-0.7814 -0.0000 -0.0000 -0.7814\n",
            "weights: 0.3214 0.6387 0.1341 -0.1140\n",
            "[[0, 1, 0], 1]:0.4264, error=0.5736, loss=0.1645, grad=-0.4693 -0.0000 -0.4693 -0.0000\n",
            "weights: 0.3261 0.6387 0.1388 -0.1140\n",
            "[[1, 0, 0], 1]:0.7464, error=0.2536, loss=0.0321, grad=-0.1123 -0.1123 -0.0000 -0.0000\n",
            "weights: 0.3272 0.6399 0.1388 -0.1140\n",
            "[[0, 1, 1], 0]:0.3382, error=-0.3382, loss=0.0572, grad=0.2995 0.0000 0.2995 0.2995\n",
            "weights: 0.3242 0.6399 0.1358 -0.1170\n",
            "[[1, 0, 1], 0]:0.6896, error=-0.6896, loss=0.2377, grad=0.3617 0.3617 0.0000 0.3617\n",
            "weights: 0.3206 0.6362 0.1358 -0.1206\n",
            "[[1, 1, 0], 0]:0.7978, error=-0.7978, loss=0.3183, grad=0.2900 0.2900 0.2900 0.0000\n",
            "weights: 0.3177 0.6333 0.1329 -0.1206\n",
            "[[1, 1, 1], 0]:0.7458, error=-0.7458, loss=0.2781, grad=0.3310 0.3310 0.3310 0.3310\n",
            "epoch61, average loss 0.1829 \n",
            "\n",
            "weights: 0.3144 0.6300 0.1296 -0.1239\n",
            "[[0, 0, 0], 0]:0.3045, error=-0.3045, loss=0.0463, grad=0.2762 0.0000 0.0000 0.0000\n",
            "weights: 0.3117 0.6300 0.1296 -0.1239\n",
            "[[0, 0, 1], 1]:0.1856, error=0.8144, loss=0.3316, grad=-0.7864 -0.0000 -0.0000 -0.7864\n",
            "weights: 0.3195 0.6300 0.1296 -0.1160\n",
            "[[0, 1, 0], 1]:0.4211, error=0.5789, loss=0.1675, grad=-0.4762 -0.0000 -0.4762 -0.0000\n",
            "weights: 0.3243 0.6300 0.1343 -0.1160\n",
            "[[1, 0, 0], 1]:0.7417, error=0.2583, loss=0.0334, grad=-0.1162 -0.1162 -0.0000 -0.0000\n",
            "weights: 0.3254 0.6312 0.1343 -0.1160\n",
            "[[0, 1, 1], 0]:0.3308, error=-0.3308, loss=0.0547, grad=0.2946 0.0000 0.2946 0.2946\n",
            "weights: 0.3225 0.6312 0.1314 -0.1190\n",
            "[[1, 0, 1], 0]:0.6830, error=-0.6830, loss=0.2332, grad=0.3644 0.3644 0.0000 0.3644\n",
            "weights: 0.3189 0.6275 0.1314 -0.1226\n",
            "[[1, 1, 0], 0]:0.7924, error=-0.7924, loss=0.3139, grad=0.2949 0.2949 0.2949 0.0000\n",
            "weights: 0.3159 0.6246 0.1284 -0.1226\n",
            "[[1, 1, 1], 0]:0.7381, error=-0.7381, loss=0.2724, grad=0.3360 0.3360 0.3360 0.3360\n",
            "epoch62, average loss 0.1816 \n",
            "\n",
            "weights: 0.3125 0.6212 0.1251 -0.1260\n",
            "[[0, 0, 0], 0]:0.3028, error=-0.3028, loss=0.0458, grad=0.2750 0.0000 0.0000 0.0000\n",
            "weights: 0.3098 0.6212 0.1251 -0.1260\n",
            "[[0, 0, 1], 1]:0.1818, error=0.8182, loss=0.3348, grad=-0.7912 -0.0000 -0.0000 -0.7912\n",
            "weights: 0.3177 0.6212 0.1251 -0.1181\n",
            "[[0, 1, 0], 1]:0.4159, error=0.5841, loss=0.1706, grad=-0.4830 -0.0000 -0.4830 -0.0000\n",
            "weights: 0.3225 0.6212 0.1299 -0.1181\n",
            "[[1, 0, 0], 1]:0.7370, error=0.2630, loss=0.0346, grad=-0.1202 -0.1202 -0.0000 -0.0000\n",
            "weights: 0.3237 0.6224 0.1299 -0.1181\n",
            "[[0, 1, 1], 0]:0.3235, error=-0.3235, loss=0.0523, grad=0.2896 0.0000 0.2896 0.2896\n",
            "weights: 0.3208 0.6224 0.1270 -0.1210\n",
            "[[1, 0, 1], 0]:0.6763, error=-0.6763, loss=0.2287, grad=0.3670 0.3670 0.0000 0.3670\n",
            "weights: 0.3172 0.6188 0.1270 -0.1246\n",
            "[[1, 1, 0], 0]:0.7868, error=-0.7868, loss=0.3095, grad=0.2997 0.2997 0.2997 0.0000\n",
            "weights: 0.3142 0.6158 0.1240 -0.1246\n",
            "[[1, 1, 1], 0]:0.7303, error=-0.7303, loss=0.2666, grad=0.3408 0.3408 0.3408 0.3408\n",
            "epoch63, average loss 0.1804 \n",
            "\n",
            "weights: 0.3108 0.6124 0.1206 -0.1281\n",
            "[[0, 0, 0], 0]:0.3011, error=-0.3011, loss=0.0453, grad=0.2738 0.0000 0.0000 0.0000\n",
            "weights: 0.3080 0.6124 0.1206 -0.1281\n",
            "[[0, 0, 1], 1]:0.1781, error=0.8219, loss=0.3378, grad=-0.7959 -0.0000 -0.0000 -0.7959\n",
            "weights: 0.3160 0.6124 0.1206 -0.1201\n",
            "[[0, 1, 0], 1]:0.4108, error=0.5892, loss=0.1736, grad=-0.4898 -0.0000 -0.4898 -0.0000\n",
            "weights: 0.3209 0.6124 0.1255 -0.1201\n",
            "[[1, 0, 0], 1]:0.7321, error=0.2679, loss=0.0359, grad=-0.1243 -0.1243 -0.0000 -0.0000\n",
            "weights: 0.3221 0.6136 0.1255 -0.1201\n",
            "[[0, 1, 1], 0]:0.3163, error=-0.3163, loss=0.0500, grad=0.2847 0.0000 0.2847 0.2847\n",
            "weights: 0.3193 0.6136 0.1226 -0.1229\n",
            "[[1, 0, 1], 0]:0.6696, error=-0.6696, loss=0.2242, grad=0.3694 0.3694 0.0000 0.3694\n",
            "weights: 0.3156 0.6099 0.1226 -0.1266\n",
            "[[1, 1, 0], 0]:0.7811, error=-0.7811, loss=0.3050, grad=0.3046 0.3046 0.3046 0.0000\n",
            "weights: 0.3125 0.6069 0.1196 -0.1266\n",
            "[[1, 1, 1], 0]:0.7223, error=-0.7223, loss=0.2608, grad=0.3455 0.3455 0.3455 0.3455\n",
            "epoch64, average loss 0.1791 \n",
            "\n",
            "weights: 0.3091 0.6034 0.1161 -0.1301\n",
            "[[0, 0, 0], 0]:0.2996, error=-0.2996, loss=0.0449, grad=0.2727 0.0000 0.0000 0.0000\n",
            "weights: 0.3064 0.6034 0.1161 -0.1301\n",
            "[[0, 0, 1], 1]:0.1745, error=0.8255, loss=0.3407, grad=-0.8004 -0.0000 -0.0000 -0.8004\n",
            "weights: 0.3144 0.6034 0.1161 -0.1221\n",
            "[[0, 1, 0], 1]:0.4057, error=0.5943, loss=0.1766, grad=-0.4964 -0.0000 -0.4964 -0.0000\n",
            "weights: 0.3193 0.6034 0.1211 -0.1221\n",
            "[[1, 0, 0], 1]:0.7272, error=0.2728, loss=0.0372, grad=-0.1285 -0.1285 -0.0000 -0.0000\n",
            "weights: 0.3206 0.6047 0.1211 -0.1221\n",
            "[[0, 1, 1], 0]:0.3092, error=-0.3092, loss=0.0478, grad=0.2796 0.0000 0.2796 0.2796\n",
            "weights: 0.3178 0.6047 0.1183 -0.1249\n",
            "[[1, 0, 1], 0]:0.6627, error=-0.6627, loss=0.2196, grad=0.3717 0.3717 0.0000 0.3717\n",
            "weights: 0.3141 0.6010 0.1183 -0.1286\n",
            "[[1, 1, 0], 0]:0.7753, error=-0.7753, loss=0.3005, grad=0.3093 0.3093 0.3093 0.0000\n",
            "weights: 0.3110 0.5979 0.1152 -0.1286\n",
            "[[1, 1, 1], 0]:0.7141, error=-0.7141, loss=0.2550, grad=0.3499 0.3499 0.3499 0.3499\n",
            "epoch65, average loss 0.1778 \n",
            "\n",
            "weights: 0.3075 0.5944 0.1117 -0.1321\n",
            "[[0, 0, 0], 0]:0.2982, error=-0.2982, loss=0.0445, grad=0.2717 0.0000 0.0000 0.0000\n",
            "weights: 0.3048 0.5944 0.1117 -0.1321\n",
            "[[0, 0, 1], 1]:0.1710, error=0.8290, loss=0.3436, grad=-0.8048 -0.0000 -0.0000 -0.8048\n",
            "weights: 0.3128 0.5944 0.1117 -0.1240\n",
            "[[0, 1, 0], 1]:0.4008, error=0.5992, loss=0.1795, grad=-0.5030 -0.0000 -0.5030 -0.0000\n",
            "weights: 0.3179 0.5944 0.1167 -0.1240\n",
            "[[1, 0, 0], 1]:0.7222, error=0.2778, loss=0.0386, grad=-0.1329 -0.1329 -0.0000 -0.0000\n",
            "weights: 0.3192 0.5957 0.1167 -0.1240\n",
            "[[0, 1, 1], 0]:0.3022, error=-0.3022, loss=0.0457, grad=0.2746 0.0000 0.2746 0.2746\n",
            "weights: 0.3165 0.5957 0.1140 -0.1268\n",
            "[[1, 0, 1], 0]:0.6558, error=-0.6558, loss=0.2150, grad=0.3738 0.3738 0.0000 0.3738\n",
            "weights: 0.3127 0.5920 0.1140 -0.1305\n",
            "[[1, 1, 0], 0]:0.7693, error=-0.7693, loss=0.2959, grad=0.3140 0.3140 0.3140 0.0000\n",
            "weights: 0.3096 0.5888 0.1109 -0.1305\n",
            "[[1, 1, 1], 0]:0.7058, error=-0.7058, loss=0.2491, grad=0.3542 0.3542 0.3542 0.3542\n",
            "epoch66, average loss 0.1765 \n",
            "\n",
            "weights: 0.3060 0.5853 0.1073 -0.1341\n",
            "[[0, 0, 0], 0]:0.2968, error=-0.2968, loss=0.0441, grad=0.2707 0.0000 0.0000 0.0000\n",
            "weights: 0.3033 0.5853 0.1073 -0.1341\n",
            "[[0, 0, 1], 1]:0.1677, error=0.8323, loss=0.3464, grad=-0.8089 -0.0000 -0.0000 -0.8089\n",
            "weights: 0.3114 0.5853 0.1073 -0.1260\n",
            "[[0, 1, 0], 1]:0.3959, error=0.6041, loss=0.1825, grad=-0.5095 -0.0000 -0.5095 -0.0000\n",
            "weights: 0.3165 0.5853 0.1124 -0.1260\n",
            "[[1, 0, 0], 1]:0.7172, error=0.2828, loss=0.0400, grad=-0.1374 -0.1374 -0.0000 -0.0000\n",
            "weights: 0.3179 0.5867 0.1124 -0.1260\n",
            "[[0, 1, 1], 0]:0.2953, error=-0.2953, loss=0.0436, grad=0.2695 0.0000 0.2695 0.2695\n",
            "weights: 0.3152 0.5867 0.1097 -0.1287\n",
            "[[1, 0, 1], 0]:0.6488, error=-0.6488, loss=0.2105, grad=0.3757 0.3757 0.0000 0.3757\n",
            "weights: 0.3114 0.5829 0.1097 -0.1324\n",
            "[[1, 1, 0], 0]:0.7633, error=-0.7633, loss=0.2913, grad=0.3186 0.3186 0.3186 0.0000\n",
            "weights: 0.3082 0.5797 0.1065 -0.1324\n",
            "[[1, 1, 1], 0]:0.6973, error=-0.6973, loss=0.2431, grad=0.3582 0.3582 0.3582 0.3582\n",
            "epoch67, average loss 0.1752 \n",
            "\n",
            "weights: 0.3047 0.5761 0.1030 -0.1360\n",
            "[[0, 0, 0], 0]:0.2956, error=-0.2956, loss=0.0437, grad=0.2698 0.0000 0.0000 0.0000\n",
            "weights: 0.3020 0.5761 0.1030 -0.1360\n",
            "[[0, 0, 1], 1]:0.1644, error=0.8356, loss=0.3491, grad=-0.8130 -0.0000 -0.0000 -0.8130\n",
            "weights: 0.3101 0.5761 0.1030 -0.1279\n",
            "[[0, 1, 0], 1]:0.3911, error=0.6089, loss=0.1854, grad=-0.5158 -0.0000 -0.5158 -0.0000\n",
            "weights: 0.3153 0.5761 0.1081 -0.1279\n",
            "[[1, 0, 0], 1]:0.7121, error=0.2879, loss=0.0414, grad=-0.1419 -0.1419 -0.0000 -0.0000\n",
            "weights: 0.3167 0.5776 0.1081 -0.1279\n",
            "[[0, 1, 1], 0]:0.2885, error=-0.2885, loss=0.0416, grad=0.2645 0.0000 0.2645 0.2645\n",
            "weights: 0.3140 0.5776 0.1055 -0.1305\n",
            "[[1, 0, 1], 0]:0.6417, error=-0.6417, loss=0.2059, grad=0.3775 0.3775 0.0000 0.3775\n",
            "weights: 0.3103 0.5738 0.1055 -0.1343\n",
            "[[1, 1, 0], 0]:0.7572, error=-0.7572, loss=0.2866, grad=0.3231 0.3231 0.3231 0.0000\n",
            "weights: 0.3070 0.5706 0.1022 -0.1343\n",
            "[[1, 1, 1], 0]:0.6887, error=-0.6887, loss=0.2372, grad=0.3620 0.3620 0.3620 0.3620\n",
            "epoch68, average loss 0.1739 \n",
            "\n",
            "weights: 0.3034 0.5669 0.0986 -0.1379\n",
            "[[0, 0, 0], 0]:0.2944, error=-0.2944, loss=0.0433, grad=0.2689 0.0000 0.0000 0.0000\n",
            "weights: 0.3007 0.5669 0.0986 -0.1379\n",
            "[[0, 0, 1], 1]:0.1614, error=0.8386, loss=0.3517, grad=-0.8168 -0.0000 -0.0000 -0.8168\n",
            "weights: 0.3089 0.5669 0.0986 -0.1298\n",
            "[[0, 1, 0], 1]:0.3863, error=0.6137, loss=0.1883, grad=-0.5221 -0.0000 -0.5221 -0.0000\n",
            "weights: 0.3141 0.5669 0.1038 -0.1298\n",
            "[[1, 0, 0], 1]:0.7069, error=0.2931, loss=0.0429, grad=-0.1466 -0.1466 -0.0000 -0.0000\n",
            "weights: 0.3156 0.5684 0.1038 -0.1298\n",
            "[[0, 1, 1], 0]:0.2818, error=-0.2818, loss=0.0397, grad=0.2594 0.0000 0.2594 0.2594\n",
            "weights: 0.3130 0.5684 0.1012 -0.1324\n",
            "[[1, 0, 1], 0]:0.6346, error=-0.6346, loss=0.2013, grad=0.3790 0.3790 0.0000 0.3790\n",
            "weights: 0.3092 0.5646 0.1012 -0.1361\n",
            "[[1, 1, 0], 0]:0.7509, error=-0.7509, loss=0.2819, grad=0.3275 0.3275 0.3275 0.0000\n",
            "weights: 0.3059 0.5613 0.0980 -0.1361\n",
            "[[1, 1, 1], 0]:0.6800, error=-0.6800, loss=0.2312, grad=0.3656 0.3656 0.3656 0.3656\n",
            "epoch69, average loss 0.1725 \n",
            "\n",
            "weights: 0.3023 0.5577 0.0943 -0.1398\n",
            "[[0, 0, 0], 0]:0.2934, error=-0.2934, loss=0.0430, grad=0.2681 0.0000 0.0000 0.0000\n",
            "weights: 0.2996 0.5577 0.0943 -0.1398\n",
            "[[0, 0, 1], 1]:0.1584, error=0.8416, loss=0.3541, grad=-0.8205 -0.0000 -0.0000 -0.8205\n",
            "weights: 0.3078 0.5577 0.0943 -0.1316\n",
            "[[0, 1, 0], 1]:0.3817, error=0.6183, loss=0.1911, grad=-0.5282 -0.0000 -0.5282 -0.0000\n",
            "weights: 0.3131 0.5577 0.0996 -0.1316\n",
            "[[1, 0, 0], 1]:0.7017, error=0.2983, loss=0.0445, grad=-0.1514 -0.1514 -0.0000 -0.0000\n",
            "weights: 0.3146 0.5592 0.0996 -0.1316\n",
            "[[0, 1, 1], 0]:0.2753, error=-0.2753, loss=0.0379, grad=0.2544 0.0000 0.2544 0.2544\n",
            "weights: 0.3120 0.5592 0.0970 -0.1341\n",
            "[[1, 0, 1], 0]:0.6274, error=-0.6274, loss=0.1968, grad=0.3804 0.3804 0.0000 0.3804\n",
            "weights: 0.3082 0.5554 0.0970 -0.1379\n",
            "[[1, 1, 0], 0]:0.7446, error=-0.7446, loss=0.2772, grad=0.3318 0.3318 0.3318 0.0000\n",
            "weights: 0.3049 0.5521 0.0937 -0.1379\n",
            "[[1, 1, 1], 0]:0.6711, error=-0.6711, loss=0.2252, grad=0.3688 0.3688 0.3688 0.3688\n",
            "epoch70, average loss 0.1712 \n",
            "\n",
            "weights: 0.3012 0.5484 0.0900 -0.1416\n",
            "[[0, 0, 0], 0]:0.2924, error=-0.2924, loss=0.0428, grad=0.2674 0.0000 0.0000 0.0000\n",
            "weights: 0.2985 0.5484 0.0900 -0.1416\n",
            "[[0, 0, 1], 1]:0.1556, error=0.8444, loss=0.3565, grad=-0.8239 -0.0000 -0.0000 -0.8239\n",
            "weights: 0.3068 0.5484 0.0900 -0.1334\n",
            "[[0, 1, 0], 1]:0.3772, error=0.6228, loss=0.1939, grad=-0.5341 -0.0000 -0.5341 -0.0000\n",
            "weights: 0.3121 0.5484 0.0954 -0.1334\n",
            "[[1, 0, 0], 1]:0.6965, error=0.3035, loss=0.0461, grad=-0.1563 -0.1563 -0.0000 -0.0000\n",
            "weights: 0.3137 0.5499 0.0954 -0.1334\n",
            "[[0, 1, 1], 0]:0.2689, error=-0.2689, loss=0.0362, grad=0.2495 0.0000 0.2495 0.2495\n",
            "weights: 0.3112 0.5499 0.0929 -0.1359\n",
            "[[1, 0, 1], 0]:0.6202, error=-0.6202, loss=0.1923, grad=0.3816 0.3816 0.0000 0.3816\n",
            "weights: 0.3074 0.5461 0.0929 -0.1397\n",
            "[[1, 1, 0], 0]:0.7381, error=-0.7381, loss=0.2724, grad=0.3360 0.3360 0.3360 0.0000\n",
            "weights: 0.3040 0.5428 0.0895 -0.1397\n",
            "[[1, 1, 1], 0]:0.6621, error=-0.6621, loss=0.2192, grad=0.3718 0.3718 0.3718 0.3718\n",
            "epoch71, average loss 0.1699 \n",
            "\n",
            "weights: 0.3003 0.5391 0.0858 -0.1434\n",
            "[[0, 0, 0], 0]:0.2916, error=-0.2916, loss=0.0425, grad=0.2668 0.0000 0.0000 0.0000\n",
            "weights: 0.2976 0.5391 0.0858 -0.1434\n",
            "[[0, 0, 1], 1]:0.1530, error=0.8470, loss=0.3587, grad=-0.8272 -0.0000 -0.0000 -0.8272\n",
            "weights: 0.3059 0.5391 0.0858 -0.1352\n",
            "[[0, 1, 0], 1]:0.3728, error=0.6272, loss=0.1967, grad=-0.5400 -0.0000 -0.5400 -0.0000\n",
            "weights: 0.3113 0.5391 0.0912 -0.1352\n",
            "[[1, 0, 0], 1]:0.6913, error=0.3087, loss=0.0477, grad=-0.1612 -0.1612 -0.0000 -0.0000\n",
            "weights: 0.3129 0.5407 0.0912 -0.1352\n",
            "[[0, 1, 1], 0]:0.2627, error=-0.2627, loss=0.0345, grad=0.2445 0.0000 0.2445 0.2445\n",
            "weights: 0.3105 0.5407 0.0888 -0.1376\n",
            "[[1, 0, 1], 0]:0.6129, error=-0.6129, loss=0.1878, grad=0.3827 0.3827 0.0000 0.3827\n",
            "weights: 0.3066 0.5368 0.0888 -0.1414\n",
            "[[1, 1, 0], 0]:0.7316, error=-0.7316, loss=0.2676, grad=0.3400 0.3400 0.3400 0.0000\n",
            "weights: 0.3032 0.5334 0.0854 -0.1414\n",
            "[[1, 1, 1], 0]:0.6531, error=-0.6531, loss=0.2132, grad=0.3745 0.3745 0.3745 0.3745\n",
            "epoch72, average loss 0.1686 \n",
            "\n",
            "weights: 0.2995 0.5297 0.0816 -0.1452\n",
            "[[0, 0, 0], 0]:0.2909, error=-0.2909, loss=0.0423, grad=0.2662 0.0000 0.0000 0.0000\n",
            "weights: 0.2968 0.5297 0.0816 -0.1452\n",
            "[[0, 0, 1], 1]:0.1505, error=0.8495, loss=0.3608, grad=-0.8302 -0.0000 -0.0000 -0.8302\n",
            "weights: 0.3051 0.5297 0.0816 -0.1369\n",
            "[[0, 1, 0], 1]:0.3686, error=0.6314, loss=0.1994, grad=-0.5457 -0.0000 -0.5457 -0.0000\n",
            "weights: 0.3106 0.5297 0.0871 -0.1369\n",
            "[[1, 0, 0], 1]:0.6860, error=0.3140, loss=0.0493, grad=-0.1663 -0.1663 -0.0000 -0.0000\n",
            "weights: 0.3123 0.5314 0.0871 -0.1369\n",
            "[[0, 1, 1], 0]:0.2566, error=-0.2566, loss=0.0329, grad=0.2397 0.0000 0.2397 0.2397\n",
            "weights: 0.3099 0.5314 0.0847 -0.1393\n",
            "[[1, 0, 1], 0]:0.6056, error=-0.6056, loss=0.1834, grad=0.3835 0.3835 0.0000 0.3835\n",
            "weights: 0.3060 0.5275 0.0847 -0.1431\n",
            "[[1, 1, 0], 0]:0.7251, error=-0.7251, loss=0.2629, grad=0.3439 0.3439 0.3439 0.0000\n",
            "weights: 0.3026 0.5241 0.0812 -0.1431\n",
            "[[1, 1, 1], 0]:0.6439, error=-0.6439, loss=0.2073, grad=0.3769 0.3769 0.3769 0.3769\n",
            "epoch73, average loss 0.1673 \n",
            "\n",
            "weights: 0.2988 0.5203 0.0775 -0.1469\n",
            "[[0, 0, 0], 0]:0.2902, error=-0.2902, loss=0.0421, grad=0.2658 0.0000 0.0000 0.0000\n",
            "weights: 0.2962 0.5203 0.0775 -0.1469\n",
            "[[0, 0, 1], 1]:0.1482, error=0.8518, loss=0.3628, grad=-0.8331 -0.0000 -0.0000 -0.8331\n",
            "weights: 0.3045 0.5203 0.0775 -0.1385\n",
            "[[0, 1, 0], 1]:0.3644, error=0.6356, loss=0.2020, grad=-0.5512 -0.0000 -0.5512 -0.0000\n",
            "weights: 0.3100 0.5203 0.0830 -0.1385\n",
            "[[1, 0, 0], 1]:0.6806, error=0.3194, loss=0.0510, grad=-0.1714 -0.1714 -0.0000 -0.0000\n",
            "weights: 0.3117 0.5220 0.0830 -0.1385\n",
            "[[0, 1, 1], 0]:0.2507, error=-0.2507, loss=0.0314, grad=0.2349 0.0000 0.2349 0.2349\n",
            "weights: 0.3094 0.5220 0.0806 -0.1409\n",
            "[[1, 0, 1], 0]:0.5983, error=-0.5983, loss=0.1790, grad=0.3841 0.3841 0.0000 0.3841\n",
            "weights: 0.3055 0.5182 0.0806 -0.1447\n",
            "[[1, 1, 0], 0]:0.7184, error=-0.7184, loss=0.2581, grad=0.3476 0.3476 0.3476 0.0000\n",
            "weights: 0.3020 0.5147 0.0772 -0.1447\n",
            "[[1, 1, 1], 0]:0.6347, error=-0.6347, loss=0.2014, grad=0.3790 0.3790 0.3790 0.3790\n",
            "epoch74, average loss 0.1660 \n",
            "\n",
            "weights: 0.2983 0.5109 0.0734 -0.1485\n",
            "[[0, 0, 0], 0]:0.2897, error=-0.2897, loss=0.0420, grad=0.2654 0.0000 0.0000 0.0000\n",
            "weights: 0.2956 0.5109 0.0734 -0.1485\n",
            "[[0, 0, 1], 1]:0.1460, error=0.8540, loss=0.3646, grad=-0.8358 -0.0000 -0.0000 -0.8358\n",
            "weights: 0.3040 0.5109 0.0734 -0.1402\n",
            "[[0, 1, 0], 1]:0.3604, error=0.6396, loss=0.2046, grad=-0.5565 -0.0000 -0.5565 -0.0000\n",
            "weights: 0.3095 0.5109 0.0789 -0.1402\n",
            "[[1, 0, 0], 1]:0.6753, error=0.3247, loss=0.0527, grad=-0.1766 -0.1766 -0.0000 -0.0000\n",
            "weights: 0.3113 0.5127 0.0789 -0.1402\n",
            "[[0, 1, 1], 0]:0.2450, error=-0.2450, loss=0.0300, grad=0.2303 0.0000 0.2303 0.2303\n",
            "weights: 0.3090 0.5127 0.0766 -0.1425\n",
            "[[1, 0, 1], 0]:0.5910, error=-0.5910, loss=0.1746, grad=0.3846 0.3846 0.0000 0.3846\n",
            "weights: 0.3051 0.5088 0.0766 -0.1463\n",
            "[[1, 1, 0], 0]:0.7117, error=-0.7117, loss=0.2533, grad=0.3512 0.3512 0.3512 0.0000\n",
            "weights: 0.3016 0.5053 0.0731 -0.1463\n",
            "[[1, 1, 1], 0]:0.6254, error=-0.6254, loss=0.1955, grad=0.3808 0.3808 0.3808 0.3808\n",
            "epoch75, average loss 0.1647 \n",
            "\n",
            "weights: 0.2978 0.5015 0.0693 -0.1501\n",
            "[[0, 0, 0], 0]:0.2893, error=-0.2893, loss=0.0419, grad=0.2651 0.0000 0.0000 0.0000\n",
            "weights: 0.2952 0.5015 0.0693 -0.1501\n",
            "[[0, 0, 1], 1]:0.1440, error=0.8560, loss=0.3663, grad=-0.8382 -0.0000 -0.0000 -0.8382\n",
            "weights: 0.3036 0.5015 0.0693 -0.1417\n",
            "[[0, 1, 0], 1]:0.3565, error=0.6435, loss=0.2070, grad=-0.5617 -0.0000 -0.5617 -0.0000\n",
            "weights: 0.3092 0.5015 0.0749 -0.1417\n",
            "[[1, 0, 0], 1]:0.6700, error=0.3300, loss=0.0545, grad=-0.1819 -0.1819 -0.0000 -0.0000\n",
            "weights: 0.3110 0.5033 0.0749 -0.1417\n",
            "[[0, 1, 1], 0]:0.2394, error=-0.2394, loss=0.0287, grad=0.2257 0.0000 0.2257 0.2257\n",
            "weights: 0.3087 0.5033 0.0727 -0.1440\n",
            "[[1, 0, 1], 0]:0.5837, error=-0.5837, loss=0.1704, grad=0.3848 0.3848 0.0000 0.3848\n",
            "weights: 0.3049 0.4995 0.0727 -0.1478\n",
            "[[1, 1, 0], 0]:0.7049, error=-0.7049, loss=0.2485, grad=0.3546 0.3546 0.3546 0.0000\n",
            "weights: 0.3013 0.4959 0.0691 -0.1478\n",
            "[[1, 1, 1], 0]:0.6160, error=-0.6160, loss=0.1897, grad=0.3823 0.3823 0.3823 0.3823\n",
            "epoch76, average loss 0.1634 \n",
            "\n",
            "weights: 0.2975 0.4921 0.0653 -0.1517\n",
            "[[0, 0, 0], 0]:0.2890, error=-0.2890, loss=0.0418, grad=0.2649 0.0000 0.0000 0.0000\n",
            "weights: 0.2949 0.4921 0.0653 -0.1517\n",
            "[[0, 0, 1], 1]:0.1422, error=0.8578, loss=0.3679, grad=-0.8404 -0.0000 -0.0000 -0.8404\n",
            "weights: 0.3033 0.4921 0.0653 -0.1433\n",
            "[[0, 1, 0], 1]:0.3527, error=0.6473, loss=0.2095, grad=-0.5667 -0.0000 -0.5667 -0.0000\n",
            "weights: 0.3089 0.4921 0.0710 -0.1433\n",
            "[[1, 0, 0], 1]:0.6646, error=0.3354, loss=0.0562, grad=-0.1872 -0.1872 -0.0000 -0.0000\n",
            "weights: 0.3108 0.4940 0.0710 -0.1433\n",
            "[[0, 1, 1], 0]:0.2341, error=-0.2341, loss=0.0274, grad=0.2213 0.0000 0.2213 0.2213\n",
            "weights: 0.3086 0.4940 0.0688 -0.1455\n",
            "[[1, 0, 1], 0]:0.5764, error=-0.5764, loss=0.1661, grad=0.3849 0.3849 0.0000 0.3849\n",
            "weights: 0.3047 0.4901 0.0688 -0.1493\n",
            "[[1, 1, 0], 0]:0.6981, error=-0.6981, loss=0.2437, grad=0.3579 0.3579 0.3579 0.0000\n",
            "weights: 0.3012 0.4866 0.0652 -0.1493\n",
            "[[1, 1, 1], 0]:0.6066, error=-0.6066, loss=0.1840, grad=0.3834 0.3834 0.3834 0.3834\n",
            "epoch77, average loss 0.1621 \n",
            "\n",
            "weights: 0.2973 0.4827 0.0613 -0.1532\n",
            "[[0, 0, 0], 0]:0.2889, error=-0.2889, loss=0.0417, grad=0.2648 0.0000 0.0000 0.0000\n",
            "weights: 0.2947 0.4827 0.0613 -0.1532\n",
            "[[0, 0, 1], 1]:0.1406, error=0.8594, loss=0.3693, grad=-0.8424 -0.0000 -0.0000 -0.8424\n",
            "weights: 0.3031 0.4827 0.0613 -0.1447\n",
            "[[0, 1, 0], 1]:0.3491, error=0.6509, loss=0.2118, grad=-0.5715 -0.0000 -0.5715 -0.0000\n",
            "weights: 0.3088 0.4827 0.0671 -0.1447\n",
            "[[1, 0, 0], 1]:0.6593, error=0.3407, loss=0.0580, grad=-0.1926 -0.1926 -0.0000 -0.0000\n",
            "weights: 0.3108 0.4847 0.0671 -0.1447\n",
            "[[0, 1, 1], 0]:0.2290, error=-0.2290, loss=0.0262, grad=0.2169 0.0000 0.2169 0.2169\n",
            "weights: 0.3086 0.4847 0.0649 -0.1469\n",
            "[[1, 0, 1], 0]:0.5692, error=-0.5692, loss=0.1620, grad=0.3848 0.3848 0.0000 0.3848\n",
            "weights: 0.3047 0.4808 0.0649 -0.1507\n",
            "[[1, 1, 0], 0]:0.6913, error=-0.6913, loss=0.2389, grad=0.3609 0.3609 0.3609 0.0000\n",
            "weights: 0.3011 0.4772 0.0613 -0.1507\n",
            "[[1, 1, 1], 0]:0.5972, error=-0.5972, loss=0.1784, grad=0.3842 0.3842 0.3842 0.3842\n",
            "epoch78, average loss 0.1608 \n",
            "\n",
            "weights: 0.2973 0.4734 0.0574 -0.1546\n",
            "[[0, 0, 0], 0]:0.2888, error=-0.2888, loss=0.0417, grad=0.2647 0.0000 0.0000 0.0000\n",
            "weights: 0.2946 0.4734 0.0574 -0.1546\n",
            "[[0, 0, 1], 1]:0.1391, error=0.8609, loss=0.3705, grad=-0.8442 -0.0000 -0.0000 -0.8442\n",
            "weights: 0.3031 0.4734 0.0574 -0.1461\n",
            "[[0, 1, 0], 1]:0.3457, error=0.6543, loss=0.2141, grad=-0.5761 -0.0000 -0.5761 -0.0000\n",
            "weights: 0.3088 0.4734 0.0632 -0.1461\n",
            "[[1, 0, 0], 1]:0.6540, error=0.3460, loss=0.0599, grad=-0.1980 -0.1980 -0.0000 -0.0000\n",
            "weights: 0.3108 0.4753 0.0632 -0.1461\n",
            "[[0, 1, 1], 0]:0.2240, error=-0.2240, loss=0.0251, grad=0.2128 0.0000 0.2128 0.2128\n",
            "weights: 0.3087 0.4753 0.0611 -0.1483\n",
            "[[1, 0, 1], 0]:0.5620, error=-0.5620, loss=0.1579, grad=0.3845 0.3845 0.0000 0.3845\n",
            "weights: 0.3049 0.4715 0.0611 -0.1521\n",
            "[[1, 1, 0], 0]:0.6844, error=-0.6844, loss=0.2342, grad=0.3638 0.3638 0.3638 0.0000\n",
            "weights: 0.3012 0.4679 0.0574 -0.1521\n",
            "[[1, 1, 1], 0]:0.5879, error=-0.5879, loss=0.1728, grad=0.3847 0.3847 0.3847 0.3847\n",
            "epoch79, average loss 0.1595 \n",
            "\n",
            "weights: 0.2974 0.4640 0.0536 -0.1560\n",
            "[[0, 0, 0], 0]:0.2889, error=-0.2889, loss=0.0417, grad=0.2648 0.0000 0.0000 0.0000\n",
            "weights: 0.2947 0.4640 0.0536 -0.1560\n",
            "[[0, 0, 1], 1]:0.1379, error=0.8621, loss=0.3716, grad=-0.8457 -0.0000 -0.0000 -0.8457\n",
            "weights: 0.3032 0.4640 0.0536 -0.1475\n",
            "[[0, 1, 0], 1]:0.3424, error=0.6576, loss=0.2162, grad=-0.5806 -0.0000 -0.5806 -0.0000\n",
            "weights: 0.3090 0.4640 0.0594 -0.1475\n",
            "[[1, 0, 0], 1]:0.6487, error=0.3513, loss=0.0617, grad=-0.2035 -0.2035 -0.0000 -0.0000\n",
            "weights: 0.3110 0.4660 0.0594 -0.1475\n",
            "[[0, 1, 1], 0]:0.2193, error=-0.2193, loss=0.0240, grad=0.2087 0.0000 0.2087 0.2087\n",
            "weights: 0.3089 0.4660 0.0573 -0.1496\n",
            "[[1, 0, 1], 0]:0.5549, error=-0.5549, loss=0.1539, grad=0.3840 0.3840 0.0000 0.3840\n",
            "weights: 0.3051 0.4622 0.0573 -0.1534\n",
            "[[1, 1, 0], 0]:0.6776, error=-0.6776, loss=0.2295, grad=0.3665 0.3665 0.3665 0.0000\n",
            "weights: 0.3014 0.4585 0.0536 -0.1534\n",
            "[[1, 1, 1], 0]:0.5785, error=-0.5785, loss=0.1673, grad=0.3849 0.3849 0.3849 0.3849\n",
            "epoch80, average loss 0.1583 \n",
            "\n",
            "weights: 0.2976 0.4547 0.0498 -0.1573\n",
            "[[0, 0, 0], 0]:0.2891, error=-0.2891, loss=0.0418, grad=0.2649 0.0000 0.0000 0.0000\n",
            "weights: 0.2949 0.4547 0.0498 -0.1573\n",
            "[[0, 0, 1], 1]:0.1368, error=0.8632, loss=0.3726, grad=-0.8471 -0.0000 -0.0000 -0.8471\n",
            "weights: 0.3034 0.4547 0.0498 -0.1488\n",
            "[[0, 1, 0], 1]:0.3392, error=0.6608, loss=0.2183, grad=-0.5848 -0.0000 -0.5848 -0.0000\n",
            "weights: 0.3092 0.4547 0.0556 -0.1488\n",
            "[[1, 0, 0], 1]:0.6434, error=0.3566, loss=0.0636, grad=-0.2090 -0.2090 -0.0000 -0.0000\n",
            "weights: 0.3113 0.4568 0.0556 -0.1488\n",
            "[[0, 1, 1], 0]:0.2148, error=-0.2148, loss=0.0231, grad=0.2049 0.0000 0.2049 0.2049\n",
            "weights: 0.3093 0.4568 0.0536 -0.1509\n",
            "[[1, 0, 1], 0]:0.5478, error=-0.5478, loss=0.1500, grad=0.3834 0.3834 0.0000 0.3834\n",
            "weights: 0.3055 0.4529 0.0536 -0.1547\n",
            "[[1, 1, 0], 0]:0.6707, error=-0.6707, loss=0.2249, grad=0.3690 0.3690 0.3690 0.0000\n",
            "weights: 0.3018 0.4493 0.0499 -0.1547\n",
            "[[1, 1, 1], 0]:0.5691, error=-0.5691, loss=0.1619, grad=0.3848 0.3848 0.3848 0.3848\n",
            "epoch81, average loss 0.1570 \n",
            "\n",
            "weights: 0.2979 0.4454 0.0461 -0.1585\n",
            "[[0, 0, 0], 0]:0.2894, error=-0.2894, loss=0.0419, grad=0.2652 0.0000 0.0000 0.0000\n",
            "weights: 0.2953 0.4454 0.0461 -0.1585\n",
            "[[0, 0, 1], 1]:0.1359, error=0.8641, loss=0.3734, grad=-0.8482 -0.0000 -0.0000 -0.8482\n",
            "weights: 0.3037 0.4454 0.0461 -0.1501\n",
            "[[0, 1, 0], 1]:0.3362, error=0.6638, loss=0.2203, grad=-0.5888 -0.0000 -0.5888 -0.0000\n",
            "weights: 0.3096 0.4454 0.0519 -0.1501\n",
            "[[1, 0, 0], 1]:0.6381, error=0.3619, loss=0.0655, grad=-0.2145 -0.2145 -0.0000 -0.0000\n",
            "weights: 0.3118 0.4476 0.0519 -0.1501\n",
            "[[0, 1, 1], 0]:0.2105, error=-0.2105, loss=0.0221, grad=0.2011 0.0000 0.2011 0.2011\n",
            "weights: 0.3098 0.4476 0.0499 -0.1521\n",
            "[[1, 0, 1], 0]:0.5408, error=-0.5408, loss=0.1462, grad=0.3826 0.3826 0.0000 0.3826\n",
            "weights: 0.3059 0.4437 0.0499 -0.1559\n",
            "[[1, 1, 0], 0]:0.6638, error=-0.6638, loss=0.2203, grad=0.3713 0.3713 0.3713 0.0000\n",
            "weights: 0.3022 0.4400 0.0462 -0.1559\n",
            "[[1, 1, 1], 0]:0.5598, error=-0.5598, loss=0.1567, grad=0.3844 0.3844 0.3844 0.3844\n",
            "epoch82, average loss 0.1558 \n",
            "\n",
            "weights: 0.2984 0.4362 0.0424 -0.1597\n",
            "[[0, 0, 0], 0]:0.2898, error=-0.2898, loss=0.0420, grad=0.2655 0.0000 0.0000 0.0000\n",
            "weights: 0.2957 0.4362 0.0424 -0.1597\n",
            "[[0, 0, 1], 1]:0.1351, error=0.8649, loss=0.3740, grad=-0.8491 -0.0000 -0.0000 -0.8491\n",
            "weights: 0.3042 0.4362 0.0424 -0.1513\n",
            "[[0, 1, 0], 1]:0.3333, error=0.6667, loss=0.2222, grad=-0.5926 -0.0000 -0.5926 -0.0000\n",
            "weights: 0.3101 0.4362 0.0483 -0.1513\n",
            "[[1, 0, 0], 1]:0.6329, error=0.3671, loss=0.0674, grad=-0.2200 -0.2200 -0.0000 -0.0000\n",
            "weights: 0.3123 0.4384 0.0483 -0.1513\n",
            "[[0, 1, 1], 0]:0.2064, error=-0.2064, loss=0.0213, grad=0.1976 0.0000 0.1976 0.1976\n",
            "weights: 0.3104 0.4384 0.0463 -0.1532\n",
            "[[1, 0, 1], 0]:0.5338, error=-0.5338, loss=0.1425, grad=0.3817 0.3817 0.0000 0.3817\n",
            "weights: 0.3065 0.4346 0.0463 -0.1570\n",
            "[[1, 1, 0], 0]:0.6569, error=-0.6569, loss=0.2158, grad=0.3734 0.3734 0.3734 0.0000\n",
            "weights: 0.3028 0.4308 0.0426 -0.1570\n",
            "[[1, 1, 1], 0]:0.5505, error=-0.5505, loss=0.1516, grad=0.3837 0.3837 0.3837 0.3837\n",
            "epoch83, average loss 0.1546 \n",
            "\n",
            "weights: 0.2990 0.4270 0.0388 -0.1609\n",
            "[[0, 0, 0], 0]:0.2904, error=-0.2904, loss=0.0422, grad=0.2659 0.0000 0.0000 0.0000\n",
            "weights: 0.2963 0.4270 0.0388 -0.1609\n",
            "[[0, 0, 1], 1]:0.1346, error=0.8654, loss=0.3744, grad=-0.8497 -0.0000 -0.0000 -0.8497\n",
            "weights: 0.3048 0.4270 0.0388 -0.1524\n",
            "[[0, 1, 0], 1]:0.3307, error=0.6693, loss=0.2240, grad=-0.5962 -0.0000 -0.5962 -0.0000\n",
            "weights: 0.3108 0.4270 0.0447 -0.1524\n",
            "[[1, 0, 0], 1]:0.6278, error=0.3722, loss=0.0693, grad=-0.2255 -0.2255 -0.0000 -0.0000\n",
            "weights: 0.3130 0.4292 0.0447 -0.1524\n",
            "[[0, 1, 1], 0]:0.2025, error=-0.2025, loss=0.0205, grad=0.1942 0.0000 0.1942 0.1942\n",
            "weights: 0.3111 0.4292 0.0428 -0.1543\n",
            "[[1, 0, 1], 0]:0.5270, error=-0.5270, loss=0.1389, grad=0.3806 0.3806 0.0000 0.3806\n",
            "weights: 0.3073 0.4254 0.0428 -0.1581\n",
            "[[1, 1, 0], 0]:0.6501, error=-0.6501, loss=0.2113, grad=0.3753 0.3753 0.3753 0.0000\n",
            "weights: 0.3035 0.4217 0.0390 -0.1581\n",
            "[[1, 1, 1], 0]:0.5414, error=-0.5414, loss=0.1465, grad=0.3827 0.3827 0.3827 0.3827\n",
            "epoch84, average loss 0.1534 \n",
            "\n",
            "weights: 0.2997 0.4178 0.0352 -0.1620\n",
            "[[0, 0, 0], 0]:0.2910, error=-0.2910, loss=0.0424, grad=0.2664 0.0000 0.0000 0.0000\n",
            "weights: 0.2970 0.4178 0.0352 -0.1620\n",
            "[[0, 0, 1], 1]:0.1343, error=0.8657, loss=0.3748, grad=-0.8501 -0.0000 -0.0000 -0.8501\n",
            "weights: 0.3055 0.4178 0.0352 -0.1535\n",
            "[[0, 1, 0], 1]:0.3281, error=0.6719, loss=0.2257, grad=-0.5995 -0.0000 -0.5995 -0.0000\n",
            "weights: 0.3115 0.4178 0.0412 -0.1535\n",
            "[[1, 0, 0], 1]:0.6227, error=0.3773, loss=0.0712, grad=-0.2310 -0.2310 -0.0000 -0.0000\n",
            "weights: 0.3138 0.4202 0.0412 -0.1535\n",
            "[[0, 1, 1], 0]:0.1989, error=-0.1989, loss=0.0198, grad=0.1910 0.0000 0.1910 0.1910\n",
            "weights: 0.3119 0.4202 0.0393 -0.1554\n",
            "[[1, 0, 1], 0]:0.5203, error=-0.5203, loss=0.1353, grad=0.3794 0.3794 0.0000 0.3794\n",
            "weights: 0.3081 0.4164 0.0393 -0.1592\n",
            "[[1, 1, 0], 0]:0.6433, error=-0.6433, loss=0.2069, grad=0.3771 0.3771 0.3771 0.0000\n",
            "weights: 0.3044 0.4126 0.0355 -0.1592\n",
            "[[1, 1, 1], 0]:0.5323, error=-0.5323, loss=0.1417, grad=0.3815 0.3815 0.3815 0.3815\n",
            "epoch85, average loss 0.1522 \n",
            "\n",
            "weights: 0.3006 0.4088 0.0317 -0.1630\n",
            "[[0, 0, 0], 0]:0.2918, error=-0.2918, loss=0.0426, grad=0.2670 0.0000 0.0000 0.0000\n",
            "weights: 0.2979 0.4088 0.0317 -0.1630\n",
            "[[0, 0, 1], 1]:0.1341, error=0.8659, loss=0.3749, grad=-0.8503 -0.0000 -0.0000 -0.8503\n",
            "weights: 0.3064 0.4088 0.0317 -0.1545\n",
            "[[0, 1, 0], 1]:0.3258, error=0.6742, loss=0.2273, grad=-0.6027 -0.0000 -0.6027 -0.0000\n",
            "weights: 0.3124 0.4088 0.0377 -0.1545\n",
            "[[1, 0, 0], 1]:0.6176, error=0.3824, loss=0.0731, grad=-0.2365 -0.2365 -0.0000 -0.0000\n",
            "weights: 0.3148 0.4111 0.0377 -0.1545\n",
            "[[0, 1, 1], 0]:0.1955, error=-0.1955, loss=0.0191, grad=0.1880 0.0000 0.1880 0.1880\n",
            "weights: 0.3129 0.4111 0.0358 -0.1564\n",
            "[[1, 0, 1], 0]:0.5137, error=-0.5137, loss=0.1319, grad=0.3781 0.3781 0.0000 0.3781\n",
            "weights: 0.3091 0.4074 0.0358 -0.1601\n",
            "[[1, 1, 0], 0]:0.6365, error=-0.6365, loss=0.2026, grad=0.3786 0.3786 0.3786 0.0000\n",
            "weights: 0.3053 0.4036 0.0320 -0.1601\n",
            "[[1, 1, 1], 0]:0.5233, error=-0.5233, loss=0.1369, grad=0.3800 0.3800 0.3800 0.3800\n",
            "epoch86, average loss 0.1510 \n",
            "\n",
            "weights: 0.3015 0.3998 0.0282 -0.1639\n",
            "[[0, 0, 0], 0]:0.2927, error=-0.2927, loss=0.0428, grad=0.2676 0.0000 0.0000 0.0000\n",
            "weights: 0.2989 0.3998 0.0282 -0.1639\n",
            "[[0, 0, 1], 1]:0.1341, error=0.8659, loss=0.3749, grad=-0.8503 -0.0000 -0.0000 -0.8503\n",
            "weights: 0.3074 0.3998 0.0282 -0.1554\n",
            "[[0, 1, 0], 1]:0.3236, error=0.6764, loss=0.2288, grad=-0.6056 -0.0000 -0.6056 -0.0000\n",
            "weights: 0.3134 0.3998 0.0343 -0.1554\n",
            "[[1, 0, 0], 1]:0.6127, error=0.3873, loss=0.0750, grad=-0.2419 -0.2419 -0.0000 -0.0000\n",
            "weights: 0.3158 0.4022 0.0343 -0.1554\n",
            "[[0, 1, 1], 0]:0.1923, error=-0.1923, loss=0.0185, grad=0.1852 0.0000 0.1852 0.1852\n",
            "weights: 0.3140 0.4022 0.0325 -0.1573\n",
            "[[1, 0, 1], 0]:0.5072, error=-0.5072, loss=0.1286, grad=0.3767 0.3767 0.0000 0.3767\n",
            "weights: 0.3102 0.3984 0.0325 -0.1611\n",
            "[[1, 1, 0], 0]:0.6298, error=-0.6298, loss=0.1983, grad=0.3800 0.3800 0.3800 0.0000\n",
            "weights: 0.3064 0.3946 0.0287 -0.1611\n",
            "[[1, 1, 1], 0]:0.5144, error=-0.5144, loss=0.1323, grad=0.3783 0.3783 0.3783 0.3783\n",
            "epoch87, average loss 0.1499 \n",
            "\n",
            "weights: 0.3026 0.3908 0.0249 -0.1648\n",
            "[[0, 0, 0], 0]:0.2937, error=-0.2937, loss=0.0431, grad=0.2684 0.0000 0.0000 0.0000\n",
            "weights: 0.3000 0.3908 0.0249 -0.1648\n",
            "[[0, 0, 1], 1]:0.1343, error=0.8657, loss=0.3747, grad=-0.8501 -0.0000 -0.0000 -0.8501\n",
            "weights: 0.3085 0.3908 0.0249 -0.1563\n",
            "[[0, 1, 0], 1]:0.3215, error=0.6785, loss=0.2302, grad=-0.6084 -0.0000 -0.6084 -0.0000\n",
            "weights: 0.3145 0.3908 0.0310 -0.1563\n",
            "[[1, 0, 0], 1]:0.6078, error=0.3922, loss=0.0769, grad=-0.2473 -0.2473 -0.0000 -0.0000\n",
            "weights: 0.3170 0.3933 0.0310 -0.1563\n",
            "[[0, 1, 1], 0]:0.1893, error=-0.1893, loss=0.0179, grad=0.1825 0.0000 0.1825 0.1825\n",
            "weights: 0.3152 0.3933 0.0291 -0.1582\n",
            "[[1, 0, 1], 0]:0.5008, error=-0.5008, loss=0.1254, grad=0.3752 0.3752 0.0000 0.3752\n",
            "weights: 0.3114 0.3896 0.0291 -0.1619\n",
            "[[1, 1, 0], 0]:0.6231, error=-0.6231, loss=0.1942, grad=0.3812 0.3812 0.3812 0.0000\n",
            "weights: 0.3076 0.3858 0.0253 -0.1619\n",
            "[[1, 1, 1], 0]:0.5056, error=-0.5056, loss=0.1278, grad=0.3763 0.3763 0.3763 0.3763\n",
            "epoch88, average loss 0.1488 \n",
            "\n",
            "weights: 0.3039 0.3820 0.0216 -0.1657\n",
            "[[0, 0, 0], 0]:0.2948, error=-0.2948, loss=0.0435, grad=0.2692 0.0000 0.0000 0.0000\n",
            "weights: 0.3012 0.3820 0.0216 -0.1657\n",
            "[[0, 0, 1], 1]:0.1347, error=0.8653, loss=0.3744, grad=-0.8496 -0.0000 -0.0000 -0.8496\n",
            "weights: 0.3097 0.3820 0.0216 -0.1572\n",
            "[[0, 1, 0], 1]:0.3196, error=0.6804, loss=0.2315, grad=-0.6109 -0.0000 -0.6109 -0.0000\n",
            "weights: 0.3158 0.3820 0.0277 -0.1572\n",
            "[[1, 0, 0], 1]:0.6029, error=0.3971, loss=0.0788, grad=-0.2527 -0.2527 -0.0000 -0.0000\n",
            "weights: 0.3183 0.3845 0.0277 -0.1572\n",
            "[[0, 1, 1], 0]:0.1866, error=-0.1866, loss=0.0174, grad=0.1801 0.0000 0.1801 0.1801\n",
            "weights: 0.3165 0.3845 0.0259 -0.1590\n",
            "[[1, 0, 1], 0]:0.4945, error=-0.4945, loss=0.1223, grad=0.3736 0.3736 0.0000 0.3736\n",
            "weights: 0.3128 0.3808 0.0259 -0.1627\n",
            "[[1, 1, 0], 0]:0.6165, error=-0.6165, loss=0.1901, grad=0.3822 0.3822 0.3822 0.0000\n",
            "weights: 0.3089 0.3770 0.0220 -0.1627\n",
            "[[1, 1, 1], 0]:0.4969, error=-0.4969, loss=0.1235, grad=0.3742 0.3742 0.3742 0.3742\n",
            "epoch89, average loss 0.1477 \n",
            "\n",
            "weights: 0.3052 0.3732 0.0183 -0.1665\n",
            "[[0, 0, 0], 0]:0.2961, error=-0.2961, loss=0.0438, grad=0.2701 0.0000 0.0000 0.0000\n",
            "weights: 0.3025 0.3732 0.0183 -0.1665\n",
            "[[0, 0, 1], 1]:0.1352, error=0.8648, loss=0.3739, grad=-0.8490 -0.0000 -0.0000 -0.8490\n",
            "weights: 0.3110 0.3732 0.0183 -0.1580\n",
            "[[0, 1, 0], 1]:0.3179, error=0.6821, loss=0.2326, grad=-0.6132 -0.0000 -0.6132 -0.0000\n",
            "weights: 0.3171 0.3732 0.0244 -0.1580\n",
            "[[1, 0, 0], 1]:0.5982, error=0.4018, loss=0.0807, grad=-0.2580 -0.2580 -0.0000 -0.0000\n",
            "weights: 0.3197 0.3758 0.0244 -0.1580\n",
            "[[0, 1, 1], 0]:0.1840, error=-0.1840, loss=0.0169, grad=0.1778 0.0000 0.1778 0.1778\n",
            "weights: 0.3179 0.3758 0.0227 -0.1597\n",
            "[[1, 0, 1], 0]:0.4884, error=-0.4884, loss=0.1193, grad=0.3719 0.3719 0.0000 0.3719\n",
            "weights: 0.3142 0.3721 0.0227 -0.1635\n",
            "[[1, 1, 0], 0]:0.6100, error=-0.6100, loss=0.1861, grad=0.3830 0.3830 0.3830 0.0000\n",
            "weights: 0.3104 0.3683 0.0188 -0.1635\n",
            "[[1, 1, 1], 0]:0.4884, error=-0.4884, loss=0.1193, grad=0.3719 0.3719 0.3719 0.3719\n",
            "epoch90, average loss 0.1466 \n",
            "\n",
            "weights: 0.3067 0.3645 0.0151 -0.1672\n",
            "[[0, 0, 0], 0]:0.2974, error=-0.2974, loss=0.0442, grad=0.2711 0.0000 0.0000 0.0000\n",
            "weights: 0.3039 0.3645 0.0151 -0.1672\n",
            "[[0, 0, 1], 1]:0.1359, error=0.8641, loss=0.3733, grad=-0.8481 -0.0000 -0.0000 -0.8481\n",
            "weights: 0.3124 0.3645 0.0151 -0.1587\n",
            "[[0, 1, 0], 1]:0.3163, error=0.6837, loss=0.2337, grad=-0.6153 -0.0000 -0.6153 -0.0000\n",
            "weights: 0.3186 0.3645 0.0213 -0.1587\n",
            "[[1, 0, 0], 1]:0.5935, error=0.4065, loss=0.0826, grad=-0.2633 -0.2633 -0.0000 -0.0000\n",
            "weights: 0.3212 0.3672 0.0213 -0.1587\n",
            "[[0, 1, 1], 0]:0.1817, error=-0.1817, loss=0.0165, grad=0.1757 0.0000 0.1757 0.1757\n",
            "weights: 0.3195 0.3672 0.0195 -0.1605\n",
            "[[1, 0, 1], 0]:0.4824, error=-0.4824, loss=0.1164, grad=0.3702 0.3702 0.0000 0.3702\n",
            "weights: 0.3157 0.3635 0.0195 -0.1642\n",
            "[[1, 1, 0], 0]:0.6035, error=-0.6035, loss=0.1821, grad=0.3837 0.3837 0.3837 0.0000\n",
            "weights: 0.3119 0.3596 0.0157 -0.1642\n",
            "[[1, 1, 1], 0]:0.4800, error=-0.4800, loss=0.1152, grad=0.3694 0.3694 0.3694 0.3694\n",
            "epoch91, average loss 0.1455 \n",
            "\n",
            "weights: 0.3082 0.3559 0.0120 -0.1679\n",
            "[[0, 0, 0], 0]:0.2988, error=-0.2988, loss=0.0446, grad=0.2721 0.0000 0.0000 0.0000\n",
            "weights: 0.3055 0.3559 0.0120 -0.1679\n",
            "[[0, 0, 1], 1]:0.1368, error=0.8632, loss=0.3726, grad=-0.8471 -0.0000 -0.0000 -0.8471\n",
            "weights: 0.3140 0.3559 0.0120 -0.1594\n",
            "[[0, 1, 0], 1]:0.3149, error=0.6851, loss=0.2347, grad=-0.6172 -0.0000 -0.6172 -0.0000\n",
            "weights: 0.3201 0.3559 0.0181 -0.1594\n",
            "[[1, 0, 0], 1]:0.5890, error=0.4110, loss=0.0845, grad=-0.2685 -0.2685 -0.0000 -0.0000\n",
            "weights: 0.3228 0.3586 0.0181 -0.1594\n",
            "[[0, 1, 1], 0]:0.1796, error=-0.1796, loss=0.0161, grad=0.1738 0.0000 0.1738 0.1738\n",
            "weights: 0.3211 0.3586 0.0164 -0.1611\n",
            "[[1, 0, 1], 0]:0.4766, error=-0.4766, loss=0.1136, grad=0.3683 0.3683 0.0000 0.3683\n",
            "weights: 0.3174 0.3549 0.0164 -0.1648\n",
            "[[1, 1, 0], 0]:0.5972, error=-0.5972, loss=0.1783, grad=0.3842 0.3842 0.3842 0.0000\n",
            "weights: 0.3136 0.3511 0.0126 -0.1648\n",
            "[[1, 1, 1], 0]:0.4718, error=-0.4718, loss=0.1113, grad=0.3668 0.3668 0.3668 0.3668\n",
            "epoch92, average loss 0.1445 \n",
            "\n",
            "weights: 0.3099 0.3474 0.0089 -0.1685\n",
            "[[0, 0, 0], 0]:0.3003, error=-0.3003, loss=0.0451, grad=0.2732 0.0000 0.0000 0.0000\n",
            "weights: 0.3072 0.3474 0.0089 -0.1685\n",
            "[[0, 0, 1], 1]:0.1378, error=0.8622, loss=0.3717, grad=-0.8458 -0.0000 -0.0000 -0.8458\n",
            "weights: 0.3156 0.3474 0.0089 -0.1600\n",
            "[[0, 1, 0], 1]:0.3136, error=0.6864, loss=0.2356, grad=-0.6189 -0.0000 -0.6189 -0.0000\n",
            "weights: 0.3218 0.3474 0.0151 -0.1600\n",
            "[[1, 0, 0], 1]:0.5845, error=0.4155, loss=0.0863, grad=-0.2736 -0.2736 -0.0000 -0.0000\n",
            "weights: 0.3245 0.3502 0.0151 -0.1600\n",
            "[[0, 1, 1], 0]:0.1777, error=-0.1777, loss=0.0158, grad=0.1721 0.0000 0.1721 0.1721\n",
            "weights: 0.3228 0.3502 0.0134 -0.1617\n",
            "[[1, 0, 1], 0]:0.4709, error=-0.4709, loss=0.1109, grad=0.3665 0.3665 0.0000 0.3665\n",
            "weights: 0.3192 0.3465 0.0134 -0.1654\n",
            "[[1, 1, 0], 0]:0.5909, error=-0.5909, loss=0.1746, grad=0.3846 0.3846 0.3846 0.0000\n",
            "weights: 0.3153 0.3426 0.0095 -0.1654\n",
            "[[1, 1, 1], 0]:0.4637, error=-0.4637, loss=0.1075, grad=0.3640 0.3640 0.3640 0.3640\n",
            "epoch93, average loss 0.1434 \n",
            "\n",
            "weights: 0.3117 0.3390 0.0059 -0.1690\n",
            "[[0, 0, 0], 0]:0.3020, error=-0.3020, loss=0.0456, grad=0.2744 0.0000 0.0000 0.0000\n",
            "weights: 0.3089 0.3390 0.0059 -0.1690\n",
            "[[0, 0, 1], 1]:0.1390, error=0.8610, loss=0.3707, grad=-0.8444 -0.0000 -0.0000 -0.8444\n",
            "weights: 0.3174 0.3390 0.0059 -0.1606\n",
            "[[0, 1, 0], 1]:0.3124, error=0.6876, loss=0.2364, grad=-0.6204 -0.0000 -0.6204 -0.0000\n",
            "weights: 0.3236 0.3390 0.0121 -0.1606\n",
            "[[1, 0, 0], 1]:0.5801, error=0.4199, loss=0.0882, grad=-0.2786 -0.2786 -0.0000 -0.0000\n",
            "weights: 0.3264 0.3418 0.0121 -0.1606\n",
            "[[0, 1, 1], 0]:0.1760, error=-0.1760, loss=0.0155, grad=0.1705 0.0000 0.1705 0.1705\n",
            "weights: 0.3247 0.3418 0.0104 -0.1623\n",
            "[[1, 0, 1], 0]:0.4654, error=-0.4654, loss=0.1083, grad=0.3646 0.3646 0.0000 0.3646\n",
            "weights: 0.3210 0.3381 0.0104 -0.1660\n",
            "[[1, 1, 0], 0]:0.5847, error=-0.5847, loss=0.1709, grad=0.3848 0.3848 0.3848 0.0000\n",
            "weights: 0.3172 0.3343 0.0065 -0.1660\n",
            "[[1, 1, 1], 0]:0.4558, error=-0.4558, loss=0.1039, grad=0.3611 0.3611 0.3611 0.3611\n",
            "epoch94, average loss 0.1424 \n",
            "\n",
            "weights: 0.3136 0.3307 0.0029 -0.1696\n",
            "[[0, 0, 0], 0]:0.3037, error=-0.3037, loss=0.0461, grad=0.2757 0.0000 0.0000 0.0000\n",
            "weights: 0.3108 0.3307 0.0029 -0.1696\n",
            "[[0, 0, 1], 1]:0.1403, error=0.8597, loss=0.3695, grad=-0.8428 -0.0000 -0.0000 -0.8428\n",
            "weights: 0.3192 0.3307 0.0029 -0.1611\n",
            "[[0, 1, 0], 1]:0.3114, error=0.6886, loss=0.2371, grad=-0.6218 -0.0000 -0.6218 -0.0000\n",
            "weights: 0.3254 0.3307 0.0091 -0.1611\n",
            "[[1, 0, 0], 1]:0.5758, error=0.4242, loss=0.0900, grad=-0.2836 -0.2836 -0.0000 -0.0000\n",
            "weights: 0.3283 0.3335 0.0091 -0.1611\n",
            "[[0, 1, 1], 0]:0.1745, error=-0.1745, loss=0.0152, grad=0.1692 0.0000 0.1692 0.1692\n",
            "weights: 0.3266 0.3335 0.0074 -0.1628\n",
            "[[1, 0, 1], 0]:0.4600, error=-0.4600, loss=0.1058, grad=0.3627 0.3627 0.0000 0.3627\n",
            "weights: 0.3230 0.3299 0.0074 -0.1665\n",
            "[[1, 1, 0], 0]:0.5786, error=-0.5786, loss=0.1674, grad=0.3849 0.3849 0.3849 0.0000\n",
            "weights: 0.3191 0.3260 0.0036 -0.1665\n",
            "[[1, 1, 1], 0]:0.4481, error=-0.4481, loss=0.1004, grad=0.3581 0.3581 0.3581 0.3581\n",
            "epoch95, average loss 0.1414 \n",
            "\n",
            "weights: 0.3155 0.3225 0.0000 -0.1700\n",
            "[[0, 0, 0], 0]:0.3055, error=-0.3055, loss=0.0467, grad=0.2770 0.0000 0.0000 0.0000\n",
            "weights: 0.3128 0.3225 0.0000 -0.1700\n",
            "[[0, 0, 1], 1]:0.1418, error=0.8582, loss=0.3683, grad=-0.8410 -0.0000 -0.0000 -0.8410\n",
            "weights: 0.3212 0.3225 0.0000 -0.1616\n",
            "[[0, 1, 0], 1]:0.3106, error=0.6894, loss=0.2377, grad=-0.6229 -0.0000 -0.6229 -0.0000\n",
            "weights: 0.3274 0.3225 0.0062 -0.1616\n",
            "[[1, 0, 0], 1]:0.5716, error=0.4284, loss=0.0918, grad=-0.2885 -0.2885 -0.0000 -0.0000\n",
            "weights: 0.3303 0.3254 0.0062 -0.1616\n",
            "[[0, 1, 1], 0]:0.1731, error=-0.1731, loss=0.0150, grad=0.1679 0.0000 0.1679 0.1679\n",
            "weights: 0.3286 0.3254 0.0046 -0.1633\n",
            "[[1, 0, 1], 0]:0.4547, error=-0.4547, loss=0.1034, grad=0.3607 0.3607 0.0000 0.3607\n",
            "weights: 0.3250 0.3217 0.0046 -0.1669\n",
            "[[1, 1, 0], 0]:0.5725, error=-0.5725, loss=0.1639, grad=0.3849 0.3849 0.3849 0.0000\n",
            "weights: 0.3211 0.3179 0.0007 -0.1669\n",
            "[[1, 1, 1], 0]:0.4405, error=-0.4405, loss=0.0970, grad=0.3550 0.3550 0.3550 0.3550\n",
            "epoch96, average loss 0.1405 \n",
            "\n",
            "weights: 0.3176 0.3143 -0.0028 -0.1705\n",
            "[[0, 0, 0], 0]:0.3073, error=-0.3073, loss=0.0472, grad=0.2783 0.0000 0.0000 0.0000\n",
            "weights: 0.3148 0.3143 -0.0028 -0.1705\n",
            "[[0, 0, 1], 1]:0.1434, error=0.8566, loss=0.3669, grad=-0.8390 -0.0000 -0.0000 -0.8390\n",
            "weights: 0.3232 0.3143 -0.0028 -0.1621\n",
            "[[0, 1, 0], 1]:0.3098, error=0.6902, loss=0.2382, grad=-0.6239 -0.0000 -0.6239 -0.0000\n",
            "weights: 0.3294 0.3143 0.0034 -0.1621\n",
            "[[1, 0, 0], 1]:0.5675, error=0.4325, loss=0.0935, grad=-0.2932 -0.2932 -0.0000 -0.0000\n",
            "weights: 0.3324 0.3173 0.0034 -0.1621\n",
            "[[0, 1, 1], 0]:0.1720, error=-0.1720, loss=0.0148, grad=0.1669 0.0000 0.1669 0.1669\n",
            "weights: 0.3307 0.3173 0.0017 -0.1637\n",
            "[[1, 0, 1], 0]:0.4496, error=-0.4496, loss=0.1011, grad=0.3587 0.3587 0.0000 0.3587\n",
            "weights: 0.3271 0.3137 0.0017 -0.1673\n",
            "[[1, 1, 0], 0]:0.5666, error=-0.5666, loss=0.1605, grad=0.3847 0.3847 0.3847 0.0000\n",
            "weights: 0.3233 0.3098 -0.0021 -0.1673\n",
            "[[1, 1, 1], 0]:0.4331, error=-0.4331, loss=0.0938, grad=0.3518 0.3518 0.3518 0.3518\n",
            "epoch97, average loss 0.1395 \n",
            "\n",
            "weights: 0.3198 0.3063 -0.0056 -0.1708\n",
            "[[0, 0, 0], 0]:0.3093, error=-0.3093, loss=0.0478, grad=0.2797 0.0000 0.0000 0.0000\n",
            "weights: 0.3170 0.3063 -0.0056 -0.1708\n",
            "[[0, 0, 1], 1]:0.1451, error=0.8549, loss=0.3654, grad=-0.8369 -0.0000 -0.0000 -0.8369\n",
            "weights: 0.3253 0.3063 -0.0056 -0.1625\n",
            "[[0, 1, 0], 1]:0.3092, error=0.6908, loss=0.2386, grad=-0.6247 -0.0000 -0.6247 -0.0000\n",
            "weights: 0.3316 0.3063 0.0006 -0.1625\n",
            "[[1, 0, 0], 1]:0.5635, error=0.4365, loss=0.0953, grad=-0.2979 -0.2979 -0.0000 -0.0000\n",
            "weights: 0.3346 0.3093 0.0006 -0.1625\n",
            "[[0, 1, 1], 0]:0.1710, error=-0.1710, loss=0.0146, grad=0.1660 0.0000 0.1660 0.1660\n",
            "weights: 0.3329 0.3093 -0.0010 -0.1641\n",
            "[[1, 0, 1], 0]:0.4447, error=-0.4447, loss=0.0989, grad=0.3568 0.3568 0.0000 0.3568\n",
            "weights: 0.3293 0.3057 -0.0010 -0.1677\n",
            "[[1, 1, 0], 0]:0.5608, error=-0.5608, loss=0.1573, grad=0.3844 0.3844 0.3844 0.0000\n",
            "weights: 0.3255 0.3019 -0.0049 -0.1677\n",
            "[[1, 1, 1], 0]:0.4258, error=-0.4258, loss=0.0907, grad=0.3486 0.3486 0.3486 0.3486\n",
            "epoch98, average loss 0.1386 \n",
            "\n",
            "weights: 0.3220 0.2984 -0.0084 -0.1712\n",
            "[[0, 0, 0], 0]:0.3113, error=-0.3113, loss=0.0485, grad=0.2811 0.0000 0.0000 0.0000\n",
            "weights: 0.3192 0.2984 -0.0084 -0.1712\n",
            "[[0, 0, 1], 1]:0.1469, error=0.8531, loss=0.3639, grad=-0.8347 -0.0000 -0.0000 -0.8347\n",
            "weights: 0.3275 0.2984 -0.0084 -0.1628\n",
            "[[0, 1, 0], 1]:0.3087, error=0.6913, loss=0.2389, grad=-0.6254 -0.0000 -0.6254 -0.0000\n",
            "weights: 0.3338 0.2984 -0.0021 -0.1628\n",
            "[[1, 0, 0], 1]:0.5596, error=0.4404, loss=0.0970, grad=-0.3025 -0.3025 -0.0000 -0.0000\n",
            "weights: 0.3368 0.3014 -0.0021 -0.1628\n",
            "[[0, 1, 1], 0]:0.1702, error=-0.1702, loss=0.0145, grad=0.1652 0.0000 0.1652 0.1652\n",
            "weights: 0.3352 0.3014 -0.0038 -0.1645\n",
            "[[1, 0, 1], 0]:0.4399, error=-0.4399, loss=0.0968, grad=0.3548 0.3548 0.0000 0.3548\n",
            "weights: 0.3316 0.2979 -0.0038 -0.1680\n",
            "[[1, 1, 0], 0]:0.5551, error=-0.5551, loss=0.1541, grad=0.3841 0.3841 0.3841 0.0000\n",
            "weights: 0.3278 0.2940 -0.0076 -0.1680\n",
            "[[1, 1, 1], 0]:0.4187, error=-0.4187, loss=0.0877, grad=0.3453 0.3453 0.3453 0.3453\n",
            "epoch99, average loss 0.1377 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XOR\n",
        "\n",
        "see it as just two hidden nodes\n",
        "\n",
        "* d,e,g,h=1\n",
        "* b=-1\n",
        "* k=1\n",
        "* l=-2\n",
        "* rest is 0"
      ],
      "metadata": {
        "id": "3LVCUX3-4Mtp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Basic Torch"
      ],
      "metadata": {
        "id": "3d6pBw9K3_yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "import torch\n",
        "A = torch.rand((40,256,1000), dtype=torch.float16)\n",
        "x = torch.rand(1000)*9+1\n",
        "(A*x).shape"
      ],
      "metadata": {
        "id": "bt6qW1-N4Bkt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce905bf4-7f56-4cb2-b4b6-c041af97c7e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([40, 256, 1000])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AKl4enzc4r8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CoLA"
      ],
      "metadata": {
        "id": "2RIwYM6g8QQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from pandas import read_csv\n",
        "from random import shuffle\n",
        "\n",
        "hidden_size = 100\n",
        "num_classes = 1\n",
        "num_epochs = 7\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "device = \"cpu\"#torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"running on\", device)\n",
        "\n",
        "df = read_csv('/content/CoLA.tsv', sep='\\t', header=0)\n",
        "\n",
        "tokens = {}\n",
        "number_grammatical = 0\n",
        "number_nongrammatical = 0\n",
        "\n",
        "current_addr = 0\n",
        "hot_one_address = {}\n",
        "examples = []\n",
        "\n",
        "for row in df.iterrows():\n",
        "    gramatical_p = row[1].values[1]\n",
        "    sentence = row[1].values[3]\n",
        "\n",
        "    examples.append([sentence, gramatical_p])\n",
        "\n",
        "    for token in sentence.split(' '):\n",
        "        count = 1\n",
        "        if token in tokens:\n",
        "            count = tokens[token] + 1\n",
        "        else:\n",
        "            hot_one_address[token] = current_addr\n",
        "            current_addr += 1\n",
        "\n",
        "        tokens[token] = count\n",
        "\n",
        "    if gramatical_p:\n",
        "        number_grammatical += 1\n",
        "        #print(f\"{sentence}\")\n",
        "    else:\n",
        "        number_nongrammatical += 1\n",
        "        #print(f\"*{sentence}\")\n",
        "\n",
        "shuffle(examples)\n",
        "\n",
        "test_set = []\n",
        "training_set = []\n",
        "\n",
        "for i in range(len(examples)):\n",
        "    if i < 100:\n",
        "        test_set.append(examples[i])\n",
        "    else:\n",
        "        training_set.append(examples[i])\n",
        "\n",
        "num_tokens = len(tokens)\n",
        "\n",
        "# Device configuration\n",
        "\n",
        "batch_size = 100\n",
        "vocab = torch.diag(torch.ones(num_tokens,dtype=torch.float32))\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1_1 = nn.Linear(input_size, hidden_size)\n",
        "        self.l1_2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "        self.sigm = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1_1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l1_2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.sigm(out)\n",
        "        return out\n",
        "\n",
        "input_size = num_tokens\n",
        "\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "\n",
        "#criterion = nn.CrossEntropyLoss()  # remember, this does its own softmax (this should actually be BCELoss)\n",
        "criterion = nn.BCELoss()  # remember, this does its own softmax (this should actually be BCELoss)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "def train(silent=False):\n",
        "    for epoch in range(num_epochs):\n",
        "        shuffle(training_set)\n",
        "\n",
        "        for bnum in range(80):\n",
        "            batch = torch.zeros([100,num_tokens], dtype=torch.float32)\n",
        "            labels = torch.zeros([100], dtype=torch.float32)\n",
        "            for i in range(0,100):\n",
        "                for word in training_set[bnum*100 + i][0].split(' '):\n",
        "                    batch[i][hot_one_address[word]] = 1\n",
        "                labels[i] = training_set[bnum*100 + i][1]\n",
        "\n",
        "            labels.to(device)\n",
        "            batch.to(device)\n",
        "\n",
        "        # Forward pass and loss calculation\n",
        "            outputs = model(batch).squeeze()\n",
        "            loss = criterion(outputs,labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if not silent:\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}] Batch[{bnum+1}/80], Loss: {loss.item():.4f}')\n",
        "\n",
        "def evaluate():\n",
        "    n_correct = 0\n",
        "    n_samples = len(test_set)\n",
        "    with torch.no_grad():\n",
        "        batch = torch.zeros([100, num_tokens], dtype=torch.float32)\n",
        "        labels = torch.zeros([100], dtype=torch.int64)\n",
        "        for i in range(0, 100):\n",
        "            for word in test_set[i][0].split(' '):\n",
        "                batch[i][hot_one_address[word]] = 1\n",
        "            labels[i] = test_set[i][1]\n",
        "        batch.to(device)\n",
        "        labels.to(device)\n",
        "\n",
        "        outputs = model(batch).squeeze()\n",
        "        predicted = torch.round(outputs)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        acc = n_correct / n_samples\n",
        "        print(f'Accuracy of the network on the {n_samples} test images: {100 * acc:.4f} %')\n",
        "print(\"before\")\n",
        "evaluate()\n",
        "train(silent=True)\n",
        "print(\"after\")\n",
        "evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuEhXXra8S1V",
        "outputId": "9bf95e16-63bd-4829-f0cb-6ea92b659adf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running on cpu\n",
            "before\n",
            "Accuracy of the network on the 100 test images: 35.0000 %\n",
            "after\n",
            "Accuracy of the network on the 100 test images: 64.0000 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_7NCZf_zFaHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1-layer 500 nodes\n",
        "\n",
        "* before:\n",
        "Accuracy of the network on the 100 test images: 54.0000 %\n",
        "* after:\n",
        "Accuracy of the network on the 100 test images: 62.0000 %\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "2-layer 100 nodes\n",
        "* before:\n",
        "Accuracy of the network on the 100 test images: 68.0000 %\n",
        "* after:\n",
        "Accuracy of the network on the 100 test images: 70.0000 %\n",
        "\n",
        "BCE\n",
        "* before:\n",
        "Accuracy of the network on the 100 test images: 35.0000 %\n",
        "* after:\n",
        "Accuracy of the network on the 100 test images: 64.0000 %"
      ],
      "metadata": {
        "id": "NqSqaztvAId1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A_mN6NHOLbuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from pandas import read_csv\n",
        "from random import shuffle\n",
        "\n",
        "hidden_size = 100\n",
        "num_classes = 1\n",
        "num_epochs = 7\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "device = \"cpu\"#torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"running on\", device)\n",
        "\n",
        "df = read_csv('/content/CoLA.tsv', sep='\\t', header=0)\n",
        "\n",
        "tokens = {}\n",
        "number_grammatical = 0\n",
        "number_nongrammatical = 0\n",
        "\n",
        "current_addr = 0\n",
        "hot_one_address = {}\n",
        "examples = []\n",
        "\n",
        "for row in df.iterrows():\n",
        "    gramatical_p = row[1].values[1]\n",
        "    sentence = row[1].values[3]\n",
        "\n",
        "    examples.append([sentence, gramatical_p])\n",
        "\n",
        "    for token in sentence.split(' '):\n",
        "        count = 1\n",
        "        if token in tokens:\n",
        "            count = tokens[token] + 1\n",
        "        else:\n",
        "            hot_one_address[token] = current_addr\n",
        "            current_addr += 1\n",
        "\n",
        "        tokens[token] = count\n",
        "\n",
        "    if gramatical_p:\n",
        "        number_grammatical += 1\n",
        "        #print(f\"{sentence}\")\n",
        "    else:\n",
        "        number_nongrammatical += 1\n",
        "        #print(f\"*{sentence}\")\n",
        "\n",
        "shuffle(examples)\n",
        "\n",
        "test_set = []\n",
        "training_set = []\n",
        "\n",
        "for i in range(len(examples)):\n",
        "    if i < 100:\n",
        "        test_set.append(examples[i])\n",
        "    else:\n",
        "        training_set.append(examples[i])\n",
        "\n",
        "num_tokens = len(tokens)\n",
        "\n",
        "# Device configuration\n",
        "\n",
        "batch_size = 100\n",
        "vocab = torch.diag(torch.ones(num_tokens,dtype=torch.float32))\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.rnn = nn.GRU(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "        self.sigm = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.sigm(out)\n",
        "        return out\n",
        "\n",
        "input_size = num_tokens\n",
        "\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "\n",
        "#criterion = nn.CrossEntropyLoss()  # remember, this does its own softmax (this should actually be BCELoss)\n",
        "criterion = nn.BCELoss()  # remember, this does its own softmax (this should actually be BCELoss)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "def train(silent=False):\n",
        "    for epoch in range(num_epochs):\n",
        "        shuffle(training_set)\n",
        "\n",
        "        for bnum in range(80):\n",
        "            batch = torch.zeros([100,num_tokens], dtype=torch.float32)\n",
        "            labels = torch.zeros([100], dtype=torch.float32)\n",
        "            for i in range(0,100):\n",
        "                for word in training_set[bnum*100 + i][0].split(' '):\n",
        "                    batch[i][hot_one_address[word]] = 1\n",
        "                labels[i] = training_set[bnum*100 + i][1]\n",
        "\n",
        "            labels.to(device)\n",
        "            batch.to(device)\n",
        "\n",
        "        # Forward pass and loss calculation\n",
        "            outputs = model(batch).squeeze()\n",
        "            loss = criterion(outputs,labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if not silent:\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}] Batch[{bnum+1}/80], Loss: {loss.item():.4f}')\n",
        "\n",
        "def evaluate():\n",
        "    n_correct = 0\n",
        "    n_samples = len(test_set)\n",
        "    with torch.no_grad():\n",
        "        batch = torch.zeros([100, num_tokens], dtype=torch.float32)\n",
        "        labels = torch.zeros([100], dtype=torch.int64)\n",
        "        for i in range(0, 100):\n",
        "            for word in test_set[i][0].split(' '):\n",
        "                batch[i][hot_one_address[word]] = 1\n",
        "            labels[i] = test_set[i][1]\n",
        "        batch.to(device)\n",
        "        labels.to(device)\n",
        "\n",
        "        outputs = model(batch).squeeze()\n",
        "        predicted = torch.round(outputs)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        acc = n_correct / n_samples\n",
        "        print(f'Accuracy of the network on the {n_samples} test images: {100 * acc:.4f} %')\n",
        "print(\"before\")\n",
        "evaluate()\n",
        "train(silent=True)\n",
        "print(\"after\")\n",
        "evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IYlU8VV8e2M",
        "outputId": "feeaecb7-c5de-4fb6-a961-6e4959dd5b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running on cpu\n",
            "before\n",
            "Accuracy of the network on the 100 test images: 27.0000 %\n",
            "after\n",
            "Accuracy of the network on the 100 test images: 71.0000 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RNN**\n",
        "Accuracy of the network on the 100 test images: 27.0000 %\n",
        "after\n",
        "Accuracy of the network on the 100 test images: 70.0000 %\n",
        "\n",
        "**LSTM** before\n",
        "Accuracy of the network on the 100 test images: 69.0000 %\n",
        "after\n",
        "Accuracy of the network on the 100 test images: 67.0000 %\n",
        "\n",
        "**GRU**\n",
        "before\n",
        "Accuracy of the network on the 100 test images: 27.0000 %\n",
        "after\n",
        "Accuracy of the network on the 100 test images: 71.0000 %"
      ],
      "metadata": {
        "id": "ZuKgZzXYOZII"
      }
    }
  ]
}